\documentclass{article}
\usepackage{graphicx} % Required for inserting images
\usepackage{amsmath}
\usepackage{amssymb}   % Additional symbols, such as \mathbb and various math symbols
\usepackage{amsfonts}  % Additional fonts for mathematical symbols, like \mathbb
\usepackage{mathtools} % Extends amsmath with additional functionality
\usepackage{mathrsfs}  % Provides script fonts (\mathscr)
\usepackage{amsthm}    % Enhanced theorem environments (theorem, lemma, etc.)
\usepackage{bbm}
\usepackage{tikz}
\usetikzlibrary{shapes.geometric, calc}
\usepackage{array}
\usetikzlibrary{intersections, calc}
\usepackage{geometry}
\usepackage{pgfplots}


\title{Applied Probability and Statistics I - STAT400}
\author{Tom Mitchell}
\date{Mestiyage - Fall 2024}

\begin{document}

\maketitle

\section*{Syllabus}

\subsection*{Grading}
\begin{itemize}
    \item Homework — 28\% (7\% each)
    \item R Projects — 12\% (4\% each)
    \item Two exams — 30\% (15\% each)
    \item Final exam — 30\%
\end{itemize}

\subsection*{Office Hours}
\begin{itemize}
    \item Tuesday: 1:00 PM - 1:50 PM (in person, MTH 4106)
    \item Wednesday: 11:00 AM - 11:50 AM (online)
\end{itemize}

\subsection*{Exams}
\begin{itemize}
    \item 2 midterms and a final exam
\end{itemize}

\pagebreak

\section*{Lecture 1: Tuesday 8/27/2024}

\section*{Course Overview: STAT400}
We study:
\begin{enumerate}
    \item Probability
    \item Descriptive Statistics
    \item Inferential Statistics
\end{enumerate}

\subsection*{1. Probability}
\textit{Probability} is the mathematical study of uncertainty.

\subsection*{2. Descriptive Statistics}
\textit{Descriptive Statistics} involves methods for summarizing and describing the important characteristics of a dataset.

\subsection*{3. Inferential Statistics}
\textit{Inferential Statistics} involves methods for using data from a subset (sample) of a larger group (population) to make meaningful conclusions. Note that each time you pick a subset, you lose out on certain information, leading to uncertainty.

\subsection*{Setting: Conducting an Experiment}

In this course, we will often assume we are about to conduct an experiment. The possible outcomes of the experiment are known, but the exact outcome is not.

\textbf{Examples:}
\begin{itemize}
    \item Tossing a coin
    \item Rolling a die
\end{itemize}

To study these types of situations, we introduce a \textit{model for probability}.

\subsection*{Ordered Triples (\(\Omega, \mathcal{F}, P\))}
\begin{itemize}
    \item \(\Omega\) is the \textbf{sample space}: The set of all possible outcomes of the experiment.
    \item \(\mathcal{F}\) is the \textbf{event space}:
    \begin{itemize}
        \item An \textbf{event} is a subset of \(\Omega\).
        \item An event captures the idea that in many situations, we care about collections of outcomes rather than a single outcome.
        \item The event space contains collections of outcomes for which we can assign probabilities.
    \end{itemize}
    \item \(P\) is the \textbf{probability measure}:
    \[
    P: \mathcal{F} \rightarrow \mathbb{R}
    \]
    where \(P\) assigns probabilities to events.

\end{itemize}

\subsection*{Example 1: Tossing a Fair Coin}
Consider the simple experiment of tossing a \textbf{fair} coin.

\[
\Omega = \{H, T\}
\]

\[
\mathcal{F} = \{\emptyset, \{H\}, \{T\}, \{H, T\}\}
\]

\begin{itemize}
    \item \(P(\emptyset) = 0\) \\
    (``A probability of 0 represents an outcome/collection of outcomes that never takes place.")
    
    \item \(P(\{H, T\}) = 1\) \\
    (``A probability of 1 represents an outcome/collection of outcomes that always takes place.")
    
    \item \(P(\{H\}) = \frac{1}{2}\) \\
    (Requires the coin to be fair.)
    
    \item \(P(\{T\}) = \frac{1}{2}\) \\
    (Requires the coin to be fair.)
\end{itemize}

\subsection*{Example 2: Rolling a Fair Die}
Consider the experiment of rolling a fair die. Note: (\(\mathcal{P}(\Omega)\) is the Powerset of \(\Omega\))

\[
\Omega = \{1, 2, 3, 4, 5, 6\}
\]

\[
\mathcal{F} = \mathcal{P}(\Omega) =
\]
\[
\begin{aligned}
\{\emptyset, \{1\}, \{2\}, \ldots, \{6\}, \{1, 2\}, \ldots, \{1, 6\}, \{2, 3\}, \ldots, \\
\{1, 2, 3\}, \{2, 3, 4\}, \ldots, \{1, 2, 3, 4\}, \{1, 2, 3, 4, 5\}, \ldots, \Omega = \{1, 2, 3, 4, 5, 6\}\}
\end{aligned}
\]

\begin{itemize}
    \item \(P(\{i\}) = \frac{1}{6}\) for \(i = 1, 2, 3, 4, 5, 6\)
    \item \(P(\emptyset) = 0\)
    \item \(P(\Omega) = 1\)
    \item \(P(\{1, 2\}) = ?\) \\
    (Listing out probabilities for each event is \textbf{not} feasible.)
\end{itemize}

We would want a way to calculate the probability of a particular event by using the ``base" probabilities.

\textit{We will look at these rules for computing probabilities of complicated events in terms of basic ones in a bit.}

\subsection*{Example 3: Tossing a Fair Coin Until We See Heads for the First Time}
Consider the experiment of tossing a fair coin repeatedly until we observe heads for the first time, then we stop.

\[
\Omega = \{(H), (T, H), (T, T, H), (T, T, T, H), \ldots\}
\]

\[
\mathcal{F} = \mathcal{P}(\Omega)
\]

Let \(A_i\) be the event of seeing heads on the \(i\)th toss.

\[
P(A_i) = \frac{1}{2^i}
\]

\textbf{Question:} What is the probability of seeing heads on an even-numbered toss?

\[
Q = P(\text{seeing heads on an even-numbered toss}) = ?
\]

\subsection*{Example 4: Picking a Number from the Interval [0, 1]}
Consider picking a number from the interval \([0, 1]\) such that the probabilities of selecting numbers from two subintervals \(I_1\) and \(I_2\) of \([0, 1]\) are the same whenever \(I_1\) and \(I_2\) have the same length.

\[
\Omega = [0, 1]
\]

\[
\mathcal{F} = \mathcal{P}(\Omega)
\]

\[
P(\text{selecting a number from a subinterval } I \text{ of } [0, 1]) = \text{length}(I)
\]

\[
P([0, \frac{1}{4}]) = \frac{1}{4} - 0 = \frac{1}{4}
\]

\[
P([0, \frac{1}{2}]) = \frac{1}{2} - 0 = \frac{1}{2}
\]

\[
P\left(\left\{\frac{1}{2}\right\}\right) = P\left(\left[\frac{1}{2}, \frac{1}{2}\right]\right) = \frac{1}{2} - \frac{1}{2} = 0
\]

``The probability of 0 indicates an event that does not take place or an event that is so unlikely that the only reasonable value to assign to it is 0, i.e., an event that almost surely does not take place."

On Thursday will learn how to compute problems similar to \(P(\mathbb{Q} \cap [0, 1])\) = ?


\pagebreak

\section*{Lecture 2: Thursday 8/29/2024}

\subsection*{Probability}

\begin{itemize}
    \item Mathematical study of uncertainty.
\end{itemize}

\subsection*{Probability Space}

\[
(\Omega, F, P)
\]

\begin{itemize}
    \item \(\Omega\) - All possible outcomes of the experiment of interest.
    \item \(F\) - Contains events, i.e., collections of outcomes we would like to assign probabilities to.
    \item \(P\) - Probability measure.
\end{itemize}

\[
P: F \rightarrow \mathbb{R}
\]

On Tuesday, we discussed examples and introduced some formulas to compute probabilities of ``basic" events.

\subsection*{Goal for Today}

Explore how to compute probabilities of ``complicated" events in terms of basic events.

\subsection*{Two Questions}

\begin{enumerate}
    \item How do we express a complicated event in terms of basic ones?
    \item What rules can be used to compute probabilities once Question 1 has been answered?
\end{enumerate}

\begin{itemize}
    \item Question 1 is best answered by using tools from set theory.
\end{itemize}

\[
\rightarrow \text{We treat } \Omega \text{ as the list of all possible outcomes.}
\]
\[
\rightarrow \text{Events are sublists of } \Omega.
\]

Since we are only interested in outcomes (or combinations thereof) of the experiment, we treat \(\Omega\) as the universal set (i.e., we pretend that nothing outside of \(\Omega\) exists).

\subsection*{Pictorial Representation}

\begin{center}
\begin{tikzpicture}
    \draw[thick] (0,0) rectangle (4,2);
    \node at (-0.5,2) {\(\Omega\)};
\end{tikzpicture}
\end{center}

\pagebreak

We can manipulate collections of events to obtain new events in various ways:

\begin{itemize}
    \item Intersections
    \item Unions
    \item Relative complements
\end{itemize}

Given events \(A\) and \(B\), the intersection is the event that contains all outcomes common to both \(A\) and \(B\). We denote this by \(A \cap B\).

\subsection*{Intersection of Two Events}

\begin{center}
\begin{tikzpicture}
    % Draw the rectangle representing the universal set Omega
    \draw[thick] (-2,-2) rectangle (4,2);
    
    % Draw the circles representing sets A and B
    \begin{scope}
        \clip (0,0) circle(1.5);
        \fill[gray!30] (2,0) circle(1.5);
    \end{scope}
    \draw (0,0) circle(1.5);
    \draw (2,0) circle(1.5);
    
    % Label the sets
    \node at (-0.8,1.5) {\(A\)};
    \node at (2.8,1.5) {\(B\)};
    
    % Label the intersection area
    \node at (1,0) {\(A \cap B\)};
    
\end{tikzpicture}
\end{center}

\subsection*{Example}

\[
\Omega = \{1, 2, 3, 4, 5, 6\}
\]

Let \(A = \{1, 3, 5\}\) and \(B = \{4, 5\}\). Then, the intersection of \(A\) and \(B\) is:

\[
A \cap B = \{5\}
\]

\subsection*{Extending the Intersection to Families of Events}

The idea of the intersection of events can be extended to families of events.

\[
\bigcap_{i=1}^{3} A_i = (A_1 \cap A_2) \cap A_3
\]

For an infinite family of events:

\[
\bigcap_{i=1}^{\infty} A_i = A_1 \cap A_2 \cap A_3 \cap A_4 \cap A_5 \cap \ldots
\]


\subsection*{Disjoint Events}

Two events are said to be disjoint if \(A \cap B = \emptyset\).

\begin{itemize}
    \item Events \(A_1, \ldots, A_n\) are said to be disjoint if \(\textstyle \bigcap_{i=1}^{n} A_i = \emptyset \).

    \item Events \(A_1, \ldots, A_n, \ldots\) are said to be disjoint if \(\textstyle \bigcap_{i=1}^{\infty} A_i = \emptyset \).
 
    \item Events \(A_1, A_2, \ldots\) are said to be pairwise disjoint if \(A_i \cap A_j = \emptyset\) for all \(i \neq j\).
\end{itemize}

\subsection*{Example}

Consider the sample space \(\Omega = \{1, 2, 3, 4, 5, 6\}\) with the following events:

\[
A = \{1, 3, 5\}, \quad B = \{4, 5\}, \quad C = \{6\}
\]

Here, \(A\), \(B\), and \(C\) are disjoint events, meaning:

\[
A \cap B \cap C = \emptyset
\]

However, they are not pairwise disjoint, because:

\[
A \cap B = \{5\} \neq \emptyset
\]

\subsection*{Pairwise Disjoint Sets}

\begin{center}
\begin{tikzpicture}

    % Draw the rectangle representing the universal set Omega
    \draw[thick] (-2,-2) rectangle (4,2);
    
    % Draw non-intersecting circles representing pairwise disjoint sets
    \draw (0,0.5) circle(0.4);
    \draw (2,0.5) circle(0.4);
    \draw (1,-1) circle(0.4);
    
    % Label the sets
    \node at (-0.5,1.2) {\(A\)};
    \node at (2.5,1.2) {\(B\)};
    \node at (1,-1.7) {\(C\)};
    
\end{tikzpicture}
\end{center}


The word ``and" usually translates to intersection when discussing sets or events. Conversely, the word ``or" translates to a union.

\subsection*{Unions}

The union of two events \(A\) and \(B\), denoted by \(A \cup B\), is the event that contains all outcomes that are in \(A\), \(B\), or both.

\subsection*{Venn Diagram: Union of Two Sets}

\begin{center}
\begin{tikzpicture}

    % Draw the rectangle representing the universal set Omega
    \draw[thick] (-2,-2) rectangle (4,2);
    
    % Draw the circles representing sets A and B
    \begin{scope}
        \clip (0,0) circle(1.5);
        \fill[gray!30] (2,0) circle(1.5);
    \end{scope}
    \fill[gray!30] (0,0) circle(1.5);
    \fill[gray!30] (2,0) circle(1.5);
    \draw (0,0) circle(1.5);
    \draw (2,0) circle(1.5);
    
    % Label the sets
    \node at (-0.8,1.5) {\(A\)};
    \node at (2.8,1.5) {\(B\)};
    \node at (1,-2.5) {\(A \cup B\) (shaded region)};
    
\end{tikzpicture}
\end{center}

\subsection*{Example}

Consider the sample space \(\Omega = \{1, 2, 3, 4, 5, 6\}\) with the following events:

\[
A = \{1, 3, 5\}, \quad B = \{2, 3, 5\}
\]

The union of \(A\) and \(B\) is:

\[
A \cup B = \{1, 2, 3, 5\}
\]


\subsection*{Infinite and Finite Unions}

Infinite versions of unions and finite versions of unions with more than two sets can be similarly defined.

\[
\bigcup_{i=1}^{3} A_i = A_1 \cup A_2 \cup A_3
\]

Similarly, the union of more than two finite sets can be defined as:

\[
\bigcup_{i=1}^{n} A_i = A_1 \cup A_2 \cup \ldots \cup A_n
\]

Unions can also be extended to infinite collections of sets. For example, the union of an infinite sequence of sets \(A_1, A_2, \ldots\) is denoted as:

\[
\bigcup_{i=1}^{\infty} A_i = A_1 \cup A_2 \cup \ldots
\]



\subsection*{Relative Complements}

Given events \(A\) and \(B\), the relative complement \(A - B\) is the event that contains only the outcomes that are \textbf{unique} to \(A\).

\subsection*{Venn Diagram: Unique to A (\(A - B\))}

\begin{center}
\begin{tikzpicture}

    % Draw the rectangle representing the universal set Omega
    \draw[thick] (-2,-2) rectangle (4,2);
    
    % Draw the circles representing sets A and B
    \fill[gray!30] (0,0) circle(1.5);
    \begin{scope}
        \clip (2,0) circle(1.5);
        \fill[white] (0,0) circle(1.5);
    \end{scope}
    \draw (0,0) circle(1.5);
    \draw (2,0) circle(1.5);
    
    % Label the sets
    \node at (-0.8,1.5) {\(A\)};
    \node at (2.8,1.5) {\(B\)};
    \node at (-0.5,0) {\(A - B\)};
    
\end{tikzpicture}
\end{center}

\subsection*{Example}

Consider the sample space \(\Omega = \{1, 2, 3, 4, 5, 6\}\) with the following events:

\[
A = \{1, 2, 3\}, \quad B = \{2, 4, 5\}
\]

The relative complements are:

\[
A - B = \{1, 3\}, \quad B - A = \{4, 5\}
\]


\subsection*{Complement of A}

We use \(A^c\) to denote the complement of \(A\) within the universal set \(\Omega\), which is the set of outcomes that are not in \(A\):

\[
A^c = \Omega - A = \{4, 5, 6\}
\]

The word \textbf{not} is associated with complements and the phrases ``and not", ``but not" are associated with relative compliments

\subsection*{Aside (for the HW): Verifying Set Identities with Venn Diagrams}

We can use Venn diagrams to verify set identities. For example, let's verify the identity:

\[
(A \cap B)^c = A^c \cup B^c
\]

Venn diagrams representing set operations of (left hand side) LHS and (right hand side) RHS respectively are shown below:

\begin{figure}[htbp]
\centering
\begin{tikzpicture}
    \node at (0, 3) {\textbf{LHS}};
    \node at (7, 3) {\textbf{RHS}};
    % Left Column - Top (A \cap B)
    \node at (0, 0) {
        \begin{tikzpicture}
            \node at (1,2.5) {\(A \cap B\)};
            % Draw the rectangle representing the universal set Omega
            \draw[thick] (-2,-2) rectangle (4,2);
            
            % Draw A and B with intersection filled
            \begin{scope}
                \clip (0,0) circle(1.5);
            \end{scope}
            \begin{scope}
                \clip (2,0) circle(1.5);
                \fill[gray!30] (0,0) circle(1.5);
            \end{scope}
            \draw (0,0) circle(1.5);
            \draw (2,0) circle(1.5);
            
            % Label the sets
            \node at (-0.8,1.5) {\(A\)};
            \node at (2.8,1.5) {\(B\)};
        \end{tikzpicture}
    };

    % Left Column - Bottom (Complement of A \cap B)
    \node at (0, -6) {
        \begin{tikzpicture}
            \node at (1,2.5) {\((A \cap B)^c\)};
            % Draw the rectangle representing the universal set Omega
            \draw[thick] (-2,-2) rectangle (4,2);
            
            % Draw (A \cap B)^c
            \fill[gray!30] (-2,-2) rectangle (4,2);
            \begin{scope}
                \clip (0,0) circle(1.5);
            \end{scope}
            \begin{scope}
                \clip (2,0) circle(1.5);
                \fill[white!30] (0,0) circle(1.5);
            \end{scope}
            \draw (0,0) circle(1.5);
            \draw (2,0) circle(1.5);
            
            % Label the sets
            \node at (-0.8,1.5) {\(A\)};
            \node at (2.8,1.5) {\(B\)};
        \end{tikzpicture}
    };

    % Right Column - Top (A^c)
    \node at (7, 0) {
        \begin{tikzpicture}
            \node at (1,2.5) {\(A^c\)};
            % Draw the rectangle representing the universal set Omega
            \draw[thick] (-2,-2) rectangle (4,2);
            
            % Draw complement of A
            \fill[gray!30] (-2,-2) rectangle (4,2);
            \fill[white] (0,0) circle(1.5);
            \draw (0,0) circle(1.5);
            \draw (2,0) circle(1.5);
            
            % Label the sets
            \node at (-0.8,1.5) {\(A\)};
            \node at (2.8,1.5) {\(B\)};
        \end{tikzpicture}
    };

    % Right Column - Middle (B^c)
    \node at (7, -6) {
        \begin{tikzpicture}
            \node at (1,2.5) {\(B^c\)};
            % Draw the rectangle representing the universal set Omega
            \draw[thick] (-2,-2) rectangle (4,2);
            
            % Draw complement of B
            \fill[gray!30] (-2,-2) rectangle (4,2);
            \fill[white] (2,0) circle(1.5);
            \draw (0,0) circle(1.5);
            \draw (2,0) circle(1.5);
            
            % Label the sets
            \node at (-0.8,1.5) {\(A\)};
            \node at (2.8,1.5) {\(B\)};
        \end{tikzpicture}
    };

    % Right Column - Bottom (A^c \cup B^c)
    \node at (7, -12) {
        \begin{tikzpicture}
            \node at (1,2.5) {\(A^c \cup B^c\)};
            % Draw the rectangle representing the universal set Omega
            \draw[thick] (-2,-2) rectangle (4,2);
            
            % Draw A^c union B^c
            \fill[gray!30] (-2,-2) rectangle (4,2);
            \begin{scope}
                \clip (0,0) circle(1.5);
            \end{scope}
            \begin{scope}
                \clip (2,0) circle(1.5);
                \fill[white!30] (0,0) circle(1.5);
            \end{scope}
            \draw (0,0) circle(1.5);
            \draw (2,0) circle(1.5);
            
            % Label the sets
            \node at (-0.8,1.5) {\(A\)};
            \node at (2.8,1.5) {\(B\)};
        \end{tikzpicture}
    };

\end{tikzpicture}
\label{fig:venn-diagrams}
\end{figure}


\pagebreak

\subsubsection*{Conclusion}

Both sides of the identity are visually represented by the same shaded region, thus confirming that:

\[
(A \cap B)^c = A^c \cup B^c
\]


The shaded regions for \((A \cap B)^c\) and \(A^c \cup B^c\) match. Therefore, \((A \cap B)^c = A^c \cup B^c\). 

\[\]

\textbf{Note}: (we are not worrying about edges cases, for example, where A and B are disjoint but the identity still holds true)

\[\]
Now that the terminology is in place, we start to answer Q2.

\section*{Axioms}

\begin{enumerate}
    \item \(P(\Omega) = 1\), \(P(\emptyset) = 0\)
    \item \(P(A) \geq 0 \quad \text{for all } A \in \mathcal{F}\)
    \item If \(A_1, A_2, \ldots, A_n, \ldots \in \mathcal{F}\) are pairwise disjoint, then 
    \[
    P\left(\bigcup_{i=1}^{\infty} A_i\right) = \sum_{i=1}^{\infty} P(A_i)
    \]
\end{enumerate}


\textbf{Example:}
Consider the problem of tossing a fair coin until we observe heads. We want to find P(heads on an even numbered toss)

Let \( A \) be the event that heads appears for the first time on an even-numbered toss.

Thus, \( A \) can be expressed as:
\[
A = \{ (T, H), (T, T, T, H), (T, T, T, T, T, H), \dots \}
\]

Recall, $A_i$ is heads on the ith toss.


\[
P(A_i) = \frac{1}{2^i}
\]


Notice that we can describe \( A \) as the union of disjoint events where heads occurs for the first time on the \( 2i \)-th toss:

\[
A = A_2 \cup A_4 \cup A_6 \cup \dots = \bigcup_{i=1}^{\infty} A_{2i}
\]

where \( A_{2i} \) is the event that heads first appears on the \( 2i \)-th toss. The probability of \( A_{2i} \) can be computed as:
\[
P(A_{2i}) = \left(\frac{1}{2}\right)^{2i}
\]

Since the events \( A_{2i} \) are pairwise disjoint, we can use axiom 3 to see the probability of \( A \) is given by:
\[
P(A) = P\left(\bigcup_{i=1}^{\infty} A_{2i}\right)
= \sum_{i=1}^{\infty} P(A_{2i}) 
= \sum_{i=1}^{\infty} \left(\frac{1}{2}\right)^{2i} = \sum_{i=1}^{\infty} \left(\frac{1}{4}\right)^{i}
\]
This series is an infinite geometric series with the first term \( a = \frac{1}{4} \) and common ratio \( r = \frac{1}{4} \): 

Recall, that a the sum of a converging infinite geometric series where \(|r| < 1\) is:
\[
S = a+ar+ar^2+... = \sum_{i=0}^{\infty} \left(ar^n\right) = \frac{a}{1 - r}
\]

Therefore:
\[
\sum_{i=1}^{\infty} \left(\frac{1}{4}\right)^i = \frac{\frac{1}{4}}{1 - \frac{1}{4}} = \frac{\frac{1}{4}}{\frac{3}{4}} = \frac{1}{3}
\]

Thus, the probability that the first occurrence of heads is on an even-numbered toss is \( \boxed{\frac{1}{3}} \).


Derived rule: If \( A_1, \dots, A_N \in \mathcal{F} \) are pairwise disjoint, then 
\[
P\left(\bigcup_{i=1}^{\infty} A_i\right) = \sum_{i=1}^{\infty} P(A_i)
\]

\textbf{Example}: Consider a fair die roll. What is the probability of rolling a 1, 3, or 5?

\[
P(\{i\}) = \frac{1}{6} \quad \text{for } i = 1, \dots, 6
\]

\[
P(\{1, 3, 5\}) = P(\{1\}) + P(\{3\}) + P(\{5\}) = \frac{1}{6} + \frac{1}{6} + \frac{1}{6} = \frac{1}{2}
\]

\pagebreak
\section*{Lecture 3: Thursday 9/3/2024}
\section{Probability}

\textbf{Definition:} Probability is the mathematical framework for quantifying and analyzing uncertainty.

A probability space is defined by the triple \( (\Omega, \mathcal{F}, P) \), where:
\begin{itemize}
    \item \( \Omega \) is the sample space (set of all possible outcomes)
    \item \( \mathcal{F} \) is the event space (sigma-algebra of subsets of \( \Omega \))
    \item \( P \) is the probability measure (function assigning probabilities to events)
\end{itemize}

\subsection*{Axioms of Probability}

The probability measure \( P \) satisfies the following axioms:
\begin{enumerate}
    \item \( P(\Omega) = 1 \) and \( P(\emptyset) = 0 \)
    \item For all \( A \in \mathcal{F} \), \( P(A) \geq 0 \)
    \item (Countable additivity) If \(A_1, A_2, \ldots \in \mathcal{F}\) are pairwise disjoint events (i.e $A_i \cap A_j = \emptyset$ for all $i \neq j$):
        \[
        P\left(\bigcup_{i=1}^{\infty} A_i\right) = \sum_{i=1}^{\infty} P(A_i)
        \]
\end{enumerate}

\textbf{Note:} Understanding and being able to derive properties from these axioms is crucial for the first midterm and for building a solid foundation in probability theory.

\subsection*{Important Results}

\begin{enumerate}  
    \item \textbf{Decomposition of Probability:} For any two events \(A, B \in \mathcal{F}\):
    \[
        P(B) = P(B - A) + P(A \cap B)
    \]

    \textit{Proof:} 
    \begin{itemize}
        \item Observe that \(B\) can be partitioned into two disjoint sets: \(B = (B - A) \cup (A \cap B)\)
        \item Note that \((B - A) \cap (A \cap B) = \emptyset\) (these sets are mutually exclusive)
        \item By the axiom of countable additivity (which implies finite additivity for disjoint events):
        \[P(B) = P((B - A) \cup (A \cap B)) = P(B - A) + P(A \cap B)\]
    \end{itemize}

    This result is fundamental in probability theory and is often used in solving complex probability problems. 
    It allows us to break down the probability of an event into mutually exclusive parts, which can be easier to calculate individually.

    \begin{center}
    \begin{tikzpicture}
        % Draw the rectangle representing the universal set Omega
        \draw[thick] (-2,-2) rectangle (4,2);
        
        % Draw the circles representing sets A and B
        \fill[gray!30] (2,0) circle(1.5);
        \begin{scope}
            \clip (0,0) circle(1.5);
        \end{scope}
        \draw (0,0) circle(1.5);
        \draw (2,0) circle(1.5);
        
        % Label the sets
        \node at (-0.8,1.5) {\(A\)};
        \node at (2.8,1.5) {\(B\)};
        \node at (1,0) {\(A \cap B\)};
        \node at (2.5,0) {\(B - A\)};
    \end{tikzpicture}
    \end{center}


    \item \textbf{Finite Additivity:} For any two events \(A, B \in \mathcal{F}\):
    \[
        P(A \cup B) = P(A) + P(B) - P(A \cap B)
    \]

    \textit{Proof:}
    \begin{itemize}
        \item Observe that \(A \cup B = A \cup (B - A)\) and \(A \cap (B - A) = \emptyset\)
        \item Since \(A\) and \(B - A\) are disjoint, \(P(A \cup B) = P(A) + P(B - A)\) (finite additivity)
        \item From the decomposition result: \(P(B) = P(B - A) + P(A \cap B)\)
        \item Rearranging: \(P(B - A) = P(B) - P(A \cap B)\)
        \item Substituting into our earlier equation:
              \[P(A \cup B) = P(A) + P(B) - P(A \cap B)\]
    \end{itemize}
    
    \begin{center}
    \begin{tikzpicture}
        % Draw the rectangle representing the universal set Omega
        \draw[thick] (-2,-2) rectangle (4,2);
        
        % Draw the circles representing sets A and B
        \fill[gray!30] (0,0) circle(1.5);
        \fill[gray!30] (2,0) circle(1.5);
        \draw (0,0) circle(1.5);
        \draw (2,0) circle(1.5);
        
        % Label the sets
        \node at (-0.8,1.5) {\(A\)};
        \node at (2.8,1.5) {\(B\)};
        \node at (1,0) {\(A \cap B\)};
        \node at (2.5,0) {\(B - A\)};
    \end{tikzpicture}
    \end{center}
    
    \item \textbf{Monotonicity:} If \(A \subseteq B\), then \(P(A) \leq P(B)\)
    
    \textit{Proof:} 
    \begin{itemize}
        \item If \(A \subseteq B\), then:
            \begin{itemize}
                \item \(B = A \cup (B - A)\)
                \item \(A \cap (B - A) = \emptyset\)
            \end{itemize}
        \item By finite additivity: \(P(B) = P(A \cup (B - A)) = P(A) + P(B - A)\)
        \item Since probabilities are non-negative, \(P(B - A) \geq 0\)
        \item Therefore, \(P(B) \geq P(A)\)
    \end{itemize}
    
    \begin{center}
    \begin{tikzpicture}
        % Draw the rectangle representing the universal set Omega
        \draw[thick] (-2,-2.5) rectangle (4,2.5);
        
        % Draw the circles representing sets A and B
        \fill[gray!30] (1,0) circle(2);
        \fill[gray!60] (1,0) circle(1);
        \draw (1,0) circle(2);
        \draw (1,0) circle(1);
        
        % Label the sets
        \node at (1.9,1) {\(A\)};
        \node at (2.8,1.5) {\(B\)};
    \end{tikzpicture}
    \end{center}
    
    \item \textbf{Union of Three Sets:} For \(A, B, C \in \mathcal{F}\):
    \[
    P(A \cup B \cup C)
    \]

    \textit{How to compute:}
    \begin{align*}
        P(A \cup B \cup C) &= P(A) + P(B \cup C) - P(A \cap (B \cup C)) \\
        &= P(A) + [P(B) + P(C) - P(B \cap C)] - P(A \cap (B \cup C)) \quad \text{(decompose the union)} \\
        &= P(A) + P(B) + P(C) - P(B \cap C) - P((A \cap B) \cup (A \cap C)) \quad \text{(by distributive law)} \\
        &= P(A) + P(B) + P(C) - P(B \cap C) - (P(A \cap B) + P(A \cap C) - P((A \cap B) \cap (A \cap C)))  \\
        &= P(A) + P(B) + P(C) - P(B \cap C) - (P(A \cap B) + P(A \cap C) - P(A \cap B \cap C))  \\
        &= P(A) + P(B) + P(C) - P(B \cap C) - P(A \cap B) - P(A \cap C) + P(A \cap B \cap C)  \\
    \end{align*}


\begin{center}
\begin{tikzpicture}
    % Draw the rectangle representing the universal set Omega
    \draw[thick] (-3,-2.5) rectangle (5,4.5);
    
    % Draw the circles representing sets A, B, and C
    \begin{scope}
        \clip (0,0) circle(2);
        \fill[gray!40] (2,0) circle(2);
        \fill[gray!40] (1,1.732) circle(2);
    \end{scope}
    \begin{scope}
        \clip (2,0) circle(2);
        \fill[gray!40] (1,1.732) circle(2);
    \end{scope}
    
    % Fill the intersection of all three circles with a darker shade
    \begin{scope}
        \clip (0,0) circle(2);
        \clip (2,0) circle(2);
        \fill[gray!80] (1,1.732) circle(2);
    \end{scope}
    
    \draw (0,0) circle(2);
    \draw (2,0) circle(2);
    \draw (1,1.732) circle(2);
    
    % Label the sets
    \node at (-2,-1.5) {\(A\)};
    \node at (4,-1.5) {\(B\)};
    \node at (1,4) {\(C\)};
    
    % Label intersections
    \node at (1,-0.8) {\small \(A \cap B - C\)};
    \node at (-0.15,1.5) {\small \(A \cap C - B\)};
    \node at (2.2,1.5) {\small \(B \cap C - A\)};
    \node at (1,0.6) {\(A \cap B \cap C\)};

    % Label regions for A, B, C only
    \node at (-1,-0.5) {\small $A - (B \cup C)$};
    \node at (3,-0.5) {\small $B - (A \cup C)$};
    \node at (1,3) {\small $C - (A \cup B)$};
    
    
\end{tikzpicture}
\end{center}


\end{enumerate}

\textbf{Example:} Suppose that $A$ and $B$ are events with $P(A) = 0.5$ and $P(B) = 0.6$. Find numbers $a$ and $b$ such that $a \leq P(A \cup B) \leq b$ and $a \leq P(A \cap B) \leq b$.

\begin{enumerate}
    \item Using the addition rule of probability:
        \[P(A \cup B) = P(A) + P(B) - P(A \cap B) = 0.5 + 0.6 - P(A \cap B) = 1.1 - P(A \cap B)\]
    
    \item Since $A \cup B \subseteq \Omega$ and $P(\Omega) = 1$, we have:
        \[P(A \cup B) \leq P(\Omega) \leq 1\]
    
    \item From steps 1 and 2:
        \[1.1 - P(A \cap B) \leq 1 \implies P(A \cap B) \geq 0.1\]
    
    \item The maximum value for $P(A \cap B)$ is $\min(P(A), P(B)) = 0.5$, because:
        \begin{itemize}
            \item $A \cap B \subseteq A$ and $A \cap B \subseteq B$
            \item Therefore, $P(A \cap B) \leq P(A)$ and $P(A \cap B) \leq P(B)$
        \end{itemize}
    
    \item We can conclude:
        \[0.1 \leq P(A \cap B) \leq 0.5\]
        \[0.6 \leq P(A \cup B) \leq 1.0\]
    
    \item To verify the lower bound for $P(A \cup B)$:
        \begin{align*}
            P(A \cup B) &= P(A) + P(B) - P(A \cap B) \\
                        &\geq P(A) + P(B) - \min(P(A), P(B)) \\
                        &= 0.5 + 0.6 - 0.5 = 0.6
        \end{align*}
\end{enumerate}

\textbf{Conclusion:} We have found that $a = 0.1$ and $b = 0.5$ satisfy $a \leq P(A \cap B) \leq b$, while $a = 0.6$ and $b = 1.0$ satisfy $a \leq P(A \cup B) \leq b$.

\textbf{Visualization:} To better understand the relationship between $A$ and $B$, consider the following Venn diagram:
\begin{center}
\begin{tikzpicture}
    % Draw the rectangle representing the universal set Omega
    \draw[thick] (-3,-2) rectangle (3,2);
    
    % Draw the circles representing sets A and B
    \begin{scope}
        \clip (-0.5,0) circle(1.5);
        \fill[gray!30] (0.5,0) circle(1.5);
    \end{scope}
    \draw (-0.5,0) circle(1.5);
    \draw (0.5,0) circle(1.5);
    
    % Label the sets
    \node at (-2.2,1) {$A$};
    \node at (2.2,1) {$B$};
    \node at (0, 0) {$A \cap B$};
    
    % Add probabilities
    \node at (-1.5,-1.7) {$P(A) = 0.5$};
    \node at (1.5,-1.7) {$P(B) = 0.6$};
    \node at (0,1.75) {$0.1 \leq P(A \cap B) \leq 0.5$};
\end{tikzpicture}
\end{center}

This visualization illustrates why $0.1 \leq P(A \cap B) \leq 0.5$ and $0.6 \leq P(A \cup B) \leq 1.0$.



\textbf{Example:} When Alice visits a certain grocery store, she:
\begin{itemize}
    \item buys apples with probability 0.4
    \item buys bananas with probability 0.7
    \item buys both with probability 0.25
\end{itemize}

Compute the probability that on her next visit to the store, Alice:
\begin{enumerate}
    \item buys either apples or bananas
    \item buys bananas but not apples
    \item buys neither apples nor bananas
\end{enumerate}

\textbf{Step 1:} Define notation and given probabilities
\begin{align*}
    A &: \text{Alice buys apples} \\
    B &: \text{Alice buys bananas}
\end{align*}

\begin{align*}
    P(A) &= 0.4 \\
    P(B) &= 0.7 \\
    P(A \cap B) &= 0.25
\end{align*}

\textbf{Note:} Symbol correspondences
\begin{itemize}
    \item $\cup$ corresponds to ``or" (union)
    \item $\cap$ corresponds to ``and" (intersection)
    \item $\complement$ corresponds to ``not" (complement)
    \item $-$ corresponds to ``and not", or ``but not" (relative complement)
\end{itemize}

\textbf{Step 2:} Calculate probabilities
\begin{enumerate}
    \item $P(A \cup B) = P(A) + P(B) - P(A \cap B) = 0.4 + 0.7 - 0.25 = 0.85$
    \item $P(B - A) = P(B) - P(A \cap B) = 0.7 - 0.25 = 0.45$
    \item $P(A^c \cap B^c) = P((A \cup B)^c) = 1 - P(A \cup B) = 1 - 0.85 = 0.15$
    
\end{enumerate}

\textbf{Note:} Important probability relationships:
\begin{align*}
    P(A) &= 1 - P(A^c) \\
    \Omega &= A \cup A^c \\
    P(\Omega) &= P(A) + P(A^c) = 1 \\
    P(A^c) &= 1 - P(A)
\end{align*}

\textbf{Computing probabilities for finite, equally likely outcomes:}
For any event $A \subseteq \Omega$, where $\Omega$ is a finite sample space with equally likely outcomes, the probability of $A$ is given by:

\[
P(A) = \frac{\text{number of elements in } A}{\text{number of elements in } \Omega} = \frac{|A|}{|\Omega|}
\]

where $|A|$ denotes the cardinality (number of elements) of set $A$.

\pagebreak

\section*{Lecture 4: Thursday 9/5/2024}

\subsection*{Probability for Finite, Equally Likely Outcomes}

Consider an experiment with finitely many outcomes, each of which is equally likely. This scenario is often referred to as ``fair" or ``uniformly at random" (with finite outcomes).

In this situation:
\begin{itemize}
    \item $\mathcal{F} = \mathcal{P}(\Omega)$
    \item For any event $A \in \mathcal{F}$, $P(A) = \frac{|A|}{|\Omega|}$
\end{itemize}

\textbf{Proof that $P(A) = \frac{|A|}{|\Omega|}$ satisfies the axioms of probability:}

\begin{enumerate}
    \item For any outcome $\omega \in \Omega$, we show $P(\{\omega\}) = \frac{1}{|\Omega|}$
    
    Let $\Omega = \{\omega_1, \omega_2, \ldots, \omega_n\}$. Then:
    \begin{itemize}
        \item $P(\{\omega_1\}) = P(\{\omega_2\}) = \cdots = P(\{\omega_n\})$ (equally likely)
        \item $\{\omega_i\}$ are pairwise disjoint for $i = 1, \ldots, n$
        \item $\Omega = \bigcup_{i=1}^{n} \{\omega_i\}$
        \item $P(\Omega) = P(\bigcup_{i=1}^{n} \{\omega_i\}) = \sum_{i=1}^{n} P(\{\omega_i\})$ (finite additivity)
    \end{itemize}
    Let $x = P(\{\omega_i\})$ for any $i$. Then:
    \begin{align*}
        1 &= P(\Omega) = nx \\
        x &= \frac{1}{n} = \frac{1}{|\Omega|}
    \end{align*}
    Therefore, $P(\{\omega_1\}) = P(\{\omega_2\}) = \cdots = P(\{\omega_n\}) = \frac{1}{|\Omega|}$

    \item For any event $A \subseteq \Omega$, we prove $P(A) = \frac{|A|}{|\Omega|}$
    
    Let $A = \{\omega_{i_1}, \omega_{i_2}, \ldots, \omega_{i_k}\}$ where $k = |A|$. Then:
    \begin{align*}
        P(A) &= P(\{\omega_{i_1}\} \cup \{\omega_{i_2}\} \cup \cdots \cup \{\omega_{i_k}\}) \\
             &= \sum_{j=1}^{k} P(\{\omega_{i_j}\}) \quad \text{(finite additivity)} \\
             &= \sum_{j=1}^{k} \frac{1}{n} \\
             &= \frac{k}{n} = \frac{|A|}{|\Omega|}
    \end{align*}
\end{enumerate}


To properly use the probability formula, we need to be able to count effectively. There are two fundamental principles of counting:

\begin{itemize}
    \item Additive principle of counting
    \item Multiplicative principle of counting
\end{itemize}

\textbf{Additive Principle of Counting:} If we have $n$ ways of doing one thing and $m$ ways of doing another thing, where both actions cannot be performed simultaneously, then there are $n + m$ ways of selecting an action.

\textbf{Example (Additive Principle):}
Suppose you own:
\begin{itemize}
    \item 6 pairs of jeans
    \item 5 pairs of slacks
\end{itemize}
Then there are $6 + 5 = 11$ ways of selecting an article of clothing.

\textbf{Multiplicative Principle of Counting:} If we have $n$ ways of doing one thing and $m$ ways of doing another thing, then there are $n \times m$ ways of performing both actions.

\textbf{Example (Multiplicative Principle):}
Continuing from the previous example, if you are packing for a trip and want to pack:
\begin{itemize}
    \item 1 pair of jeans
    \item 1 pair of slacks
\end{itemize}
There are $6 \times 5 = 30$ ways of selecting a pair of jeans and a pair of slacks.

Problems we study in this class can be categorized according to two main features:

\begin{enumerate}
    \item Replacement
    \item Order
\end{enumerate}

\noindent
Examples:
\begin{itemize}
    \item Passwords: Replacement allowed, order matters
    \item Card games: Usually no replacement, order may or may not matter (depends on the situation)
\end{itemize}

\noindent
We can visualize these categories in a 2x2 grid:

\begin{center}
\begin{tabular}{|c|c|c|}
    \hline
    & \textbf{Replacement} & \textbf{No Replacement} \\
    \hline
    \textbf{Order Matters} & \checkmark & \checkmark \\
    \hline
    \textbf{Order Doesn't Matter} & $\times$ & \checkmark \\
    \hline
\end{tabular}
\end{center}

\noindent
This grid helps us classify different probability problems based on their characteristics.
The $\checkmark$ and $\times$ are used to indicate what we will study in this class.


\textbf{Problem:} Suppose that a password consists of 10 characters. The character set contains 256 possible characters. If characters are chosen uniformly at random, what is the probability of picking a password that starts with an `A'?

\textbf{Analysis:}
\begin{itemize}
    \item Replacement: \checkmark
    \item Order matters: \checkmark
\end{itemize}

\textbf{Visualization:}
\begin{itemize}
    \item All possible passwords: 
        \[256, 256, 256, \ldots, 256\]
        \[\_\,\_\,\_\,\_\,\_\,\_\,\_\,\_\,\_\,\_\]
        (256 choices for each of the 10 slots)
    \item Passwords starting with 'A':
        \[A, 256, 256, \ldots, 256\]
        \[A\,\_\,\_\,\_\,\_\,\_\,\_\,\_\,\_\,\_\]
        (1 choice for first slot (`A'), 256 choices for each of the remaining 9 slots)
\end{itemize}

\textbf{Calculation:}
\begin{itemize}
    \item Total number of possible passwords: $256^{10}$ (256 choices for each of 10 slots)
    \item Number of passwords starting with `A': $1 \times 256^9$ (1 choice for first slot, 256 choices for each of 9 slots)
    \item Probability = $\frac{\text{Favorable outcomes}}{\text{Total outcomes}} = \frac{1 \times 256^9}{256^{10}} = \frac{1}{256}$
\end{itemize}

\textbf{Conclusion:} The probability of picking a password that starts with an `A' is $\frac{1}{256}$.

\noindent
\textbf{General Rule:} If you have a list of $n$ things to choose from, replacement is allowed, order matters, and you choose $k$ times, then there are $n^k$ possible choices.

\vspace{0.5cm}

\noindent
\textbf{New Problem:} Using the previous example (where $n = 256$ and $k = 10$), what is the probability of randomly picking a password that repeats at least one character?

\vspace{0.3cm}

\noindent
\textbf{Strategy:} It is sometimes easier to calculate the probability of the complement of an event.

\vspace{0.3cm}

\noindent
\textbf{Approach:} We will count the number of passwords where each character is unique.

\vspace{0.3cm}

\noindent
Let $A$ be the event that the randomly chosen password has no repeated characters.

$P(A^c) = 1 - P(A)$


\textbf{Number of passwords with unique characters:}
\begin{itemize}
    \item Visualization:
        \[\underbrace{256 \cdot 255 \cdot 254 \cdot 253 \cdot 252 \cdot 251 \cdot 250 \cdot 249 \cdot 248 \cdot 247}_{10\text{ positions}}\]
    \item Mathematical representation: $\prod_{i=0}^{9} (256 - i)$
    \item Probability calculation: $P(A^c) = 1 - \frac{\prod_{i=0}^{9} (256 - i)}{256^{10}}$
\end{itemize}
 
\vspace{0.5cm}

\pagebreak
\noindent
\textbf{General Formula:} When picking $k$ things out of $n$ things while keeping track of the order (where $k \leq n$):

\vspace{0.3cm}

\noindent
Number of different ways:
\begin{align*}
    &= n \cdot (n-1) \cdot (n-2) \cdot \ldots \cdot (n-k+1) \\
    &= n \cdot (n-1) \cdot (n-2) \cdot \ldots \cdot (n-k+1) \cdot \frac{(n-k) \cdot (n-k-1) \cdot \ldots \cdot 1}{(n-k) \cdot (n-k-1) \cdot \ldots \cdot 1} \\
    &= \frac{n!}{(n-k)!}
\end{align*}

Where $n!$ is defined as:
\[
    n! = \prod_{i=1}^{n} i \quad \text{and} \quad 0! = 1
\]

\vspace{0.3cm}

\noindent
$\frac{n!}{(n-k)!}$ is known as ``$n$ permute $k$", denoted as ${}^nP_k$.

\vspace{0.5cm}

\noindent
\textbf{No replacement, order does not matter:}

\noindent
The trick is to solve the problem assuming order matters, then adjust by dividing by the number of ways to order the $k$ things.

\vspace{0.3cm}

\noindent
Consider the following slots:

\[
\underbrace{\_\,\_\,\_\,\_\,\_\,\_\,\_\,\_\,\_\,\_}_{k\text{ slots}}
\]

\noindent
First, we count the number of ways to fill these slots while keeping track of the order:
\begin{itemize}
    \item This is given by ${}^nP_k = \frac{n!}{(n-k)!}$
    \item It represents the number of ways to choose and arrange $k$ items from $n$ options
\end{itemize}

However, this count includes permutations of the same $k$ items, which we don't want to distinguish. To adjust for this overcounting:
\begin{itemize}
    \item We divide by the number of ways to order $k$ items, which is $k!$
        \begin{itemize}
            \item $k!$ represents all possible permutations of the $k$ chosen items
        \end{itemize}
    \item This adjustment gives us the following formula:
        \[ \frac{{}^nP_k}{k!} = \frac{n!}{k!(n-k)!} = {}^nC_k = \binom{n}{k} \]
\end{itemize}

The result, $\binom{n}{k}$, is known as ``$n$ choose $k$". It represents the number of ways to choose $k$ items from $n$ options when the order doesn't matter.

\pagebreak

\section*{Lecture 5: Tuesday 9/10/2024}

\subsection*{No Replacement, Order Does Not Matter}

A common source of examples for this scenario is card games like poker.

\vspace{0.3cm}

\noindent
\textbf{Example:} Suppose you are dealt 5 cards from a well-shuffled deck of cards. What is the probability that you are dealt a straight (5 cards in sequence)?

\begin{itemize}
    \item A well-shuffled deck means all 52 cards are equally likely to be drawn (uniformly at random).
    \item A straight has 5 consecutive ranks but not all of the same suit.
\end{itemize}

\vspace{0.3cm}

\noindent
\textbf{Common Strategy: Undercount and Adjust}
\begin{itemize}
    \item We count a specific case and adjust for the number of cases.
    \item Recall: For $\binom{n}{k} = \frac{{}^nP_k}{k!}$, we overcounted and adjusted by dividing by $k!$.
\end{itemize}

\vspace{0.3cm}

\noindent
Let's consider a specific type of straight: one containing the ranks 9, 10, J, Q, K.

\begin{itemize}
    \item There are 4 different suits, so there are four ways to choose each rank.
    \item Total number of ways for a specific straight: $4^5 = 1024$
    \item Subtract straight flushes: $1024 - 4 = 1020$ (4 straight flushes, one for each suit)
\end{itemize}

The number of all straights is equal to $(4^5-4) \times$ number of options for the starting rank.

\begin{itemize}
    \item Ace can be considered the highest or lowest rank, but not both:
    \begin{itemize}
        \item A, 2, 3, 4, 5 \checkmark
        \item 10, J, Q, K, A \checkmark
        \item J, Q, K, A, 2 $\times$
    \end{itemize}
    \item There are 10 possible starting ranks (Ace(1) through 10)
\end{itemize}

    Therefore, the total number of straights is:

    \[ 10 \times (4^5-4) = 10 \times 1020 = 10,200 \]

    The required probability is:
    
    \begin{align*}
    P(\text{Straight}) &= \frac{\text{Number of straights}}{\text{Number of possible hands}} \\[6pt]
    &= \frac{10(4^5-4)}{\binom{52}{5}}
    \end{align*}

    \subsection*{Conditional Probability}

    Conditional probability measures the likelihood of an event occurring given that another event has already occurred. It allows us to update our probability estimates based on new information.
    
    \textbf{Definition:} Given two events $A$ and $B$, where $P(A) > 0$, the conditional probability of $B$ given that $A$ has occurred is denoted by $P(B|A)$. This probability is defined as:
    
    \[
    P(B|A) = \frac{P(A \cap B)}{P(A)}
    \]
    
    \textbf{Example:} Suppose you buy a lottery ticket and the first four numbers drawn match the numbers on your ticket. Your chances of winning have increased because we now have additional information.
    
    The formula for conditional probability can be interpreted as the proportion of outcomes in A that also belong to B. This is visually represented in the Venn diagram below:
    \begin{center}
    \begin{tikzpicture}
        % Draw the rectangle representing the universal set Omega
        \draw[thick] (-2,-2) rectangle (4,2);
        
        % Draw the circles representing sets A and B
        \begin{scope}
            \clip (0,0) circle(1.5);
            \fill[gray!30] (2,0) circle(1.5);
        \end{scope}
        \draw (0,0) circle(1.5);
        \draw (2,0) circle(1.5);
        
        % Label the sets
        \node at (-0.8,1.5) {$A$};
        \node at (2.8,1.5) {$B$};
        
        % Label the intersection area
        \node at (1,0) {$A \cap B$};
        
    \end{tikzpicture}
    \end{center}
    In this diagram, $P(B|A)$ represents the proportion of the area of $A$ that overlaps with $B$.
    
    \subsection*{Independence}
    
    Two events $A$ and $B$ are independent if:
    
    \[
    P(A \cap B) = P(A) \cdot P(B)
    \]

    \textbf{Note:} This definition holds for all values of $P(A)$ and $P(B)$, including when either or both equal zero.
    
    In the case where $P(A) > 0$, independence implies:
    
    \[
    \frac{P(A \cap B)}{P(A)} = P(B)
    \]
    
    Which is equivalent to $P(B|A) = P(B)$, meaning the occurrence of $A$ does not affect the probability of $B$.
    
    \pagebreak
    
    \section*{Lecture 6: Tuesday 9/12/2024}
    
    \subsection*{Review: Conditional Probability and Independence}
    
    On Tuesday, we discussed conditional probability and independence.
    
    \begin{itemize}
        \item Conditional Probability: $P(B|A) = \frac{P(A \cap B)}{P(A)}$, where $P(A) > 0$
        \item We added the requirement $P(B) > 0$, not necessary for the equation to hold true, but useful for computing $P(A|B)$ based on $P(B|A)$
    \end{itemize}
    
    \subsection*{Independence}
    
    Events $A$ and $B$ are independent if $P(A \cap B) = P(A)P(B)$
    
    If we assume $P(A) > 0$, then $P(B) = \frac{P(A \cap B)}{P(A)} = P(B|A)$
    
    \subsection*{Example: Rolling Two Fair Dice}
    
    Consider an experiment of rolling two fair dice. Alice and Bob are given the following question:
    
    \begin{quote}
    If Alice rolls the dice and tells Bob that the sum of the dice was 4, does this give Bob new information about whether the number 2 was rolled on the first die?
    \end{quote}
    
    \subsubsection*{Analysis}
    
    \begin{itemize}
        \item Sample Space: $\Omega = \{(i,j) | i,j = 1,2,3,4,5,6\}$
        \item $P(\{i,j\}) = \frac{1}{6} \cdot \frac{1}{6} = \frac{1}{36}$ (assuming independence)
        \item Alternate approach: All outcomes are equally likely
    \end{itemize}
    
    Let's define events:
    \begin{itemize}
        \item $A$: The sum of the numbers is 4
        \item $B$: The first die roll results in a 2
    \end{itemize}
    
    \begin{align*}
        A &= \{(1,3), (2,2), (3,1)\} \\
        B &= \{(2,1), (2,2), (2,3), (2,4), (2,5), (2,6)\} \\
        A \cap B &= \{(2,2)\}
    \end{align*}
    
    \begin{align*}
        P(B) &= \frac{6}{36} = \frac{1}{6} \\
        P(A \cap B) &= \frac{1}{36} \\
        P(B|A) &= \frac{P(A \cap B)}{P(A)} = \frac{\frac{1}{36}}{\frac{3}{36}} = \frac{1}{3} \neq \frac{1}{6} = P(B)
    \end{align*}
    Therefore, Alice's information does give Bob new information about the probability of rolling a 2 on the first die.

    \subsection*{Independence as an Assumption}

    It's important to note that independence is often an assumption, and it may not always be justified. Consider the following example:

    \subsubsection*{Sally Clark Case and SIDS}

    In the Sally Clark case, a misuse of probability led to a wrongful conviction:

    \begin{itemize}
        \item Probability of SIDS (Sudden Infant Death Syndrome) was estimated as $\frac{1}{7000}$
        \item Probability of two SIDS deaths was calculated as $(\frac{1}{7000})^2 = \frac{1}{49 \times 10^6}$
        \item This low probability was incorrectly interpreted as indicating guilt
    \end{itemize}

    However, this calculation had two major flaws:
    \begin{enumerate}
        \item The assumption of independence was not justified
        \item Low probability events do occur
    \end{enumerate}

    \subsection*{Frequentist Interpretation of Probability}

    The frequentist interpretation of probability is defined as:

    \[
    P(A) = \lim_{n \to \infty} \frac{\text{number of times A occurred}}{n}
    \]

    where $n$ is the number of independent repetitions of the experiment.

    \subsubsection*{Example: Fair Coin Toss}

    For a fair coin toss:

    \[
    P(\text{H}) = \frac{1}{2} = \lim_{n \to \infty} \frac{\text{number of heads}}{n}
    \]

    In practice, we approximate this as:

    \[
    P(\text{H}) \approx \frac{\text{number of heads observed}}{\text{total number of tosses}}
    \]

    \textbf{Note:} R Project 2 includes exercises related to these concepts.

    \subsection*{Bayes' Theorem - Required Terminology \& Proving Intermediate Results}
    
    \textbf{Note:} This will be on the list of proofs for exams.
    
    \subsubsection*{Partition}
    
    A partition of $\Omega$ is a collection of sets $\{A_\alpha : \alpha \in A\}$ such that:
    
    \begin{enumerate}
        \item $A_\alpha \cap A_\beta = \emptyset$ for all $\alpha, \beta \in A$ and $\alpha \neq \beta$
        \item $\bigcup_{\alpha \in A} A_\alpha = \Omega$
    \end{enumerate}

    Here is a visual example of a partition:
    
    \begin{center}
    \begin{tikzpicture}[scale=1.2]
        % Sample space
        \draw[thick] (0,0) rectangle (5,5);
        \node at (5.2,5.2) {$\Omega$};
        
        % Partition elements
        \fill[red!30] (0,0) -- (2,5) -- (5,3) -- cycle;
        \fill[blue!30] (0,0) -- (5,0) -- (5,3) -- cycle;
        \fill[green!30] (0,0) -- (2,5) -- (0,5) -- cycle;
        \fill[yellow!30] (2,5) -- (5,3) -- (5,5) -- cycle;
        
        % Labels
        \node at (2.5,2.5) {$A_1$};
        \node at (3.5,1.5) {$A_2$};
        \node at (1,4.5) {$A_3$};
        \node at (4,4.5) {$A_4$};
    \end{tikzpicture}
    \end{center}
    
    A partition breaks up the sample space into distinct, non-overlapping pieces.

    Note:

    1) Given $A \subseteq \Omega$, the intersections $\{A \cap A_\alpha : \alpha \in \mathcal{A}\}$ form a partition of $A$.
    
    Here is a visual example:

    \begin{center}
    \begin{tikzpicture}[scale=1.2]
        % Draw the sample space
        \draw[thick] (0,0) rectangle (5,5);
        \node at (5.2,5.2) {$\Omega$};
        
        % Define partition lines
        \draw[dotted, thick, red] (2.5,0) -- (2.5,5) node[midway, right] {$A_2$};
        \draw[dotted, thick, green] (0,2.5) -- (5,2.5) node[midway, above] {$A_3$};
        
        % Fill partition regions with light colors
        \fill[red!15] (0,0) rectangle (2.5,5); % A1
        \fill[blue!15] (2.5,0) rectangle (5,2.5); % A2
        \fill[green!15] (0,2.5) rectangle (2.5,5); % A3
        \fill[yellow!15] (2.5,2.5) rectangle (5,5); % A4
        
        % Draw set A with thick dashed line
        \draw[thick, dashed] (1,1) rectangle (4,4) node[pos=0.85, above right] {$A$};
        
        % Draw dotted lines inside A to show partitions
        \draw[dotted, thick, red] (2.5,1) -- (2.5,4);
        \draw[dotted, thick, green] (1,2.5) -- (4,2.5);
        
        % Fill intersections within A with solid colors
        \fill[red!60, opacity=0.7] (1,1) rectangle (2.5,2.5); % A ∩ A1
        \fill[blue!60, opacity=0.7] (2.5,1) rectangle (4,2.5); % A ∩ A2
        \fill[yellow!60, opacity=0.7] (2.5,2.5) rectangle (4,4); % A ∩ A4
        \fill[green!60, opacity=0.7] (1,2.5) rectangle (2.5,4); % A ∩ A3
        
        % Labels for intersections
        \node at (1.75,1.75) {$A \cap A_1$};
        \node at (3.25,1.75) {$A \cap A_2$};
        \node at (3.25,3.25) {$A \cap A_4$};
        \node at (1.75,3.25) {$A \cap A_3$};
        
    \end{tikzpicture}
    \end{center}
    
    We typically consider problems where the partition $\{A_i\}$ is finite. That is, the partition splits up the sample space into finitely many non-overlapping pieces. For example, we might have $|\{A_i\}| = 2$ or $|\{A_i\}| = 3$.

    \vspace{0.5cm}

    \textbf{Law of Total Probability}

    Let $\{A_1, \ldots, A_n\}$ be a partition of the sample space $\Omega$ with $P(A_i) > 0$ for all $i$, and let $B$ be an event with $P(B) > 0$. Then:

    \begin{equation*}
    P(B) = \sum_{i=1}^n P(A_i \cap B) = \sum_{i=1}^n P(B|A_i)P(A_i)
    \end{equation*}

    This law allows us to calculate the probability of an event $B$ by considering its interaction with each part of the partition.


    \section*{Lecture 7: Tuesday 9/17/2024}

    \subsection*{Conditional Probability}

    \begin{itemize}
        \item \textbf{Definition of Conditional Probability}
        \item \textbf{Independence}
        \item \textbf{Bayes' Theorem}
    \end{itemize}

    \subsubsection*{Partition}
    A \textbf{partition} of the sample space \(\Omega\) is a collection \( \{B_1, \dots, B_n\} \) of events such that:
    \begin{align*}
        B_i \cap B_j &= \emptyset \quad \text{for all } i \neq j, \\
        \bigcup_{i=1}^{n} B_i &= \Omega.
    \end{align*}

    The diagrams above illustrate how the sample space is split into non-overlapping regions.

    \subsubsection*{Law of Total Probability}
    Suppose that \( \{B_1, \dots, B_n\} \) is a partition of the sample space \(\Omega\) with \( P(B_i) > 0 \) for all \(i\). Then, for any event \( A \) with \( P(A) > 0 \), we have:
    \[
        P(A) = \sum_{i=1}^{n} P(A \cap B_i) = \sum_{i=1}^{n} P(A \mid B_i) P(B_i)
    \]

    Consider the event \( A \), where 
    \[
        A = \bigcup_{i=1}^{n} (A \cap B_i)
    \]

    Note that the events \( A \cap B_i \) are pairwise disjoint (as shown in the above diagram).

    \[
        P(A) = P\left( \bigcup_{i=1}^{n} A \cap B_i \right) = \sum_{i=1}^{n} P(A \cap B_i)
    \]

    Additionally, the conditional probability is given by:
    \[
        P(A \mid B_i) = \frac{P(A \cap B_i)}{P(B_i)}
    \]

    Therefore:
    \[
        P(A \cap B_i) = P(A \mid B_i) P(B_i)
    \]
    \[
        P(A) = \sum_{i=1}^{n} P(A \mid B_i) P(B_i)
    \]

    \subsubsection*{Bayes' Theorem}
    
    Suppose \( B_1, B_2, \ldots, B_n \) is a partition of the sample space \( \Omega \) with \( P(B_i) > 0 \) for all \( i \). Let \( A \) be an event with \( P(A) > 0 \). Then, for any \( k \) where \( 1 \leq k \leq n \),
    
    \[
        P(B_k \mid A) = \frac{P(A \mid B_k) P(B_k)}{\sum_{j=1}^{n} P(A \mid B_j) P(B_j)}
    \]
    
    \textbf{Proof:} By the definition of conditional probability,
    
    \[
        P(B_k \mid A) = \frac{P(A \cap B_k)}{P(A)} = \frac{P(A \mid B_k) P(B_k)}{P(A)}
    \]
    
    Using the Law of Total Probability,
    
    \[
        P(A) = \sum_{j=1}^{n} P(A \mid B_j) P(B_j)
    \]
    
    Therefore,
    
    \[
        P(B_k \mid A) = \frac{P(A \mid B_k) P(B_k)}{\sum_{j=1}^{n} P(A \mid B_j) P(B_j)}
    \]
    
    The Law of Total Probability allows us to change the order of conditioning.
    
    \textbf{Example:} Suppose an experiment consists of tossing a fair coin followed by rolling a fair die if the coin comes up heads, and rolling a fair four-sided die if it comes up tails.
    
    What is the probability that we see heads given that we see a one?
    
    Let \( H \) be the event that the coin comes up heads, and \( F \) be the event that the die rolls a one. Then,
    
    \[
        P(F) = P(F \mid H) P(H) + P(F \mid T) P(T)
    \]
    \begin{figure}[h!]
        \centering
        \begin{tikzpicture}[
            grow=right,
            level distance=4cm,
            level 1/.style={sibling distance=6cm},
            level 2/.style={sibling distance=1.3cm},
            every node/.style={align=center, font=\small}
        ]
            \node {Start}
                child { 
                    node {Tails (T)}
                        child { node {1} edge from parent node[above] {\(\frac{1}{4}\)} }
                        child { node {2} edge from parent node[above] {\(\frac{1}{4}\)} }
                        child { node {3} edge from parent node[above] {\(\frac{1}{4}\)} }
                        child { node {4} edge from parent node[above] {\(\frac{1}{4}\)} }
                    edge from parent node[above] {\(\frac{1}{2}\)}
                }
                child { 
                    node {Heads (H)}
                        child { node {1} edge from parent node[above] {\(\frac{1}{6}\)} }
                        child { node {2} edge from parent node[above] {\(\frac{1}{6}\)} }
                        child { node {3} edge from parent node[above] {\(\frac{1}{6}\)} }
                        child { node {4} edge from parent node[above] {\(\frac{1}{6}\)} }
                        child { node {5} edge from parent node[above] {\(\frac{1}{6}\)} }
                        child { node {6} edge from parent node[above] {\(\frac{1}{6}\)} }
                    edge from parent node[above] {\(\frac{1}{2}\)}
                };
        \end{tikzpicture}
        \caption{Experiment Diagram: Coin Toss and Die Roll}
        \label{fig:coin-die-diagram}
    \end{figure}

    \textbf{Solution:}
    
    We are to find \( P(H \mid F) \).

    \[
        \Omega = \{ (H, 1), (H, 2), (H, 3), (H, 4), (H, 5), (H, 6), (T, 1), (T, 2), (T, 3), (T, 4) \}
    \]

    \textbf{Bayes' Theorem:} Let \( H \) be the event that the coin comes up heads, and \( T \) be the event that it comes up tails.

    \begin{itemize}
        \item \( P(H) = \frac{1}{2} = P(T) \)
        \item \( H \cup T = \Omega \)
        \item \( H \cap T = \emptyset \)
    \end{itemize}

    \pagebreak

    Thus, \( H \) and \( T \) form a partition of \( \Omega \).

    \[
        P(i \mid H) = \frac{1}{6} \quad \text{for all } i \in \{1, 2, 3, 4, 5, 6\}
    \]

    \[
        P(i \mid T) = \frac{1}{4} \quad \text{for all } i \in \{1, 2, 3, 4\}
    \]

    \textbf{Bayes' Theorem:}
    
    \[
        P(\text{Heads} \mid \text{One}) = \frac{P(\text{One} \mid \text{Heads}) \cdot P(\text{Heads})}{P(\text{One} \mid \text{Heads}) \cdot P(\text{Heads}) + P(\text{One} \mid \text{Tails}) \cdot P(\text{Tails})}
    \]

    Using Bayes' Theorem,

    \[
        P(H \mid F) = \frac{P(F \mid H) \cdot P(H)}{P(F \mid H) \cdot P(H) + P(F \mid T) \cdot P(T)}
    \]

    Plugging in the values,

    \[
        P(H \mid F) = \frac{\left(\frac{1}{6}\right) \cdot \left(\frac{1}{2}\right)}{\left(\frac{1}{6} \cdot \frac{1}{2}\right) + \left(\frac{1}{4} \cdot \frac{1}{2}\right)} 
        = \frac{\frac{1}{12}}{\frac{1}{12} + \frac{1}{8}} 
        = \frac{\frac{1}{12}}{\frac{5}{24}} 
        = \frac{2}{5}
    \]

    Therefore, the probability that the coin was heads given that we saw a one is \( \boxed{\frac{2}{5}} \).
    
    \textbf{Problem Statement:}
    
    A doctor is called to see a sick child in a particular neighborhood. The doctor has prior information that sick children in the neighborhood are suffering from either measles or the flu, and no child has both. Additionally, the doctor knows that:
    \begin{itemize}
        \item \(90\%\) of sick children have measles.
        \item The probability that a child with measles has a rash is \(0.95\).
        \item The probability that a child with the flu has a rash is \(0.08\).
    \end{itemize}
    
    The child that the doctor sees has a rash. What is the probability that the child has measles?
    
    \bigskip
    
    \textbf{Definitions:}
    \begin{itemize}
        \item \(\Omega\): Sick children from the neighborhood.
        \item \(M\): The child has measles.
        \item \(F\): The child has the flu.
        \item \(R\): The child has a rash.
    \end{itemize}
    
    \(M\) and \(F\) form a partition of the sample space \(\Omega\).
    
    \pagebreak
    
    \textbf{Given:}
    \[
        P(M) = 0.1, \quad P(F) = 0.9
    \]
    \[
        P(R \mid M) = 0.95, \quad P(R \mid F) = 0.08
    \]
    
    \bigskip
    
    \textbf{Applying Bayes' Theorem:}
    \[
        P(M \mid R) = \frac{P(R \mid M) \cdot P(M)}{P(R \mid M) \cdot P(M) + P(R \mid F) \cdot P(F)}
    \]
    
    \[
        = \frac{0.95 \times 0.1}{0.95 \times 0.1 + 0.08 \times 0.9}
    \]
    
    \[
        = \frac{0.095}{0.095 + 0.072} = \frac{0.095}{0.167} \approx 0.569
    \]
    
    \bigskip
    
    \textbf{Conclusion:} The probability that the child has measles given that the child has a rash is approximately \( \boxed{0.569} \).

    \textbf{Problem Statement:}
    Suppose that you have 3 cards identical in every way except for their color. One card is red on both sides, one card is blue on both sides, and one card is red on one side and blue on the other. 
    You put the cards into a hat and mix them up. You pick one and put it on a desk. You see the color red. What is the probability that the other side is blue?

    \bigskip

    Let \(RR\) denote card 1, \(BB\) denote card 2, and \(RB\) denote card 3.

    Let \(R\) be the event that we see red when we put the card on the desk.

    \(RB\), \(BB\), and \(RR\) form a partition of \(\omega\).

    \[
        P(RB) = P(BB) = P(RR) = \frac{1}{3}
    \]

    \[
        P(R \mid RB) = \frac{1}{2}, \quad P(R \mid BB) = 0, \quad P(R \mid RR) = 1
    \]

    \[
        P(RB \mid R) = \frac{P(R \mid RB) \cdot P(RB)}{P(R \mid RR) \cdot P(RR) + P(R \mid RB) \cdot P(RB) + P(R \mid BB) \cdot P(BB)}
    \]

    \[
        P(RB \mid R) = \frac{\left(\frac{1}{2}\right) \cdot \left(\frac{1}{3}\right)}{\left(\frac{1}{2}\right) \cdot \left(\frac{1}{3}\right) + 0 \cdot \left(\frac{1}{3}\right) + 1 \cdot \left(\frac{1}{3}\right)} = \frac{\frac{1}{6}}{\frac{1}{6} + 0 + \frac{1}{3}} = \frac{\frac{1}{6}}{\frac{1}{2}} = \boxed{\frac{1}{3}}
    \]

    \pagebreak

    \section*{Lecture 8: Thursday 9/19/2024}

    \section*{Random Variables}

    A \textbf{random variable} is a function from the sample space to the real numbers.
    \[
        X : \Omega \to \mathbb{R}
    \]

    \textbf{Notes:}
    \begin{itemize}
        \item The actual definition has a lot more technicalities to rule out pathologies. We will not worry about these.
    \end{itemize}

    Random variables are based on the fact that in many situations we care about a value associated with our pick from the sample space rather than the pick itself.

    \textbf{Example:} A study involving the effect of a new medication on blood pressure.

    A random variable is a function. Thinking in terms of examples may better highlight why the terminology is what it is.

    In order for a random variable to be useful, we should be able to compute 
    \[
        P(X \in A) = P(\{\omega : X(\omega) \in A\}) \quad \text{for } A \subseteq \mathbb{R}.
    \]
   

    \(P(X \in A)\) is the probability of running across an outcome that causes the function to take a value inside of \(A\).

    \textbf{Example (cont):}
    \[
        P(X \in [119, 125]) = P(\{\omega \mid X(\omega) \in [119, 125]\})
    \]

    \textbf{How do we convey this information?}

    \textbf{Distribution function for a random variable \(X\):}
    \[
        D_X : \mathcal{P}(\mathbb{R}) \to \mathbb{R}
    \]
    \[
        D_X(A) = P(X \in A)
    \]

    Since \(\mathcal{P}(\mathbb{R})\) contains very complicated subsets of real numbers, it is unlikely that we are able to express \(D_X\) in a form that is suitable for computation.

    For a random variable \(X\), the \textbf{cumulative distribution function} (CDF) is defined as:
    \[
        F_X : \mathbb{R} \to \mathbb{R}
    \]
    \[
        F_X(a) = P(X \leq a) = P(X \in (-\infty, a])
    \]

    Suppose that an experiment consists of tossing a fair coin. Let \(X\) track the outcome of the coin toss in the natural way. (\(\Omega = \{H, T\}\)) Define \(X(T) = 0\) and \(X(H) = 1\). Compute the CDF and the distribution function of \(X\).

    \[
        F_X(a) = P(X \leq a)
    \]

    Suppose \(a = -1.32975\):
    \[
        F_X(a) = P(X \leq a) = 0
    \]
    since no outcome of \(X\) can have a value less than \(a\).

    Note, this is true for any \(a < 0\):
    \[
        F_X(a) = 0 \quad \text{for all } a < 0
    \]

    Suppose \(a = 0\):
    \[
        F_X(0) = P(X \leq 0) = \frac{1}{2}
    \]

    Suppose \(a = 0.5\):
    \[
        F_X(a) = P(X \leq 0.5) = P(X = 0) = \frac{1}{2}
    \]

    Suppose \(0 \leq a < 1\):
    \[
        F_X(a) = \frac{1}{2}
    \]

    Suppose \(a = 1\):
    \[
        F_X(a) = P(X \leq a) = P(X \leq 1) = P(X = 0 \text{ or } X = 1) = 1
    \]

    Suppose \(a = 1.5\) so \(a > 1\):
    \[
        F_X(a) = P(X \leq a) = P(X \leq 1.5) = 1
    \]
    since any outcome of \(X\) must be less than or equal to 1.


    \begin{figure}[h!]
        \centering
        \begin{tikzpicture}[scale=1.5]
            % Axes
            \draw[->] (-0.5,0) -- (2.5,0) node[right] {$a$};
            \draw[->] (0,-0.5) -- (0,1.5) node[above] {$F_X(a)$};
            
            % Function
            \draw[thick] (-0.5,0) -- (0,0);
            \draw[thick] (0,0.5) -- (1,0.5);
            \draw[thick] (1,1) -- (2.5,1);
            
            % Points
            \fill (0,0.5) circle (1.5pt);
            \fill (1,1) circle (1.5pt);
            
            % Open circles
            \draw (0,0) circle (1.5pt);
            \draw (1,0.5) circle (1.5pt);
            
            % Labels
            \node[below] at (-0.1,0) {0};
            \node[below] at (1,-0.1) {1};
            \node[left] at (0,0.5) {0.5};
            \node[left] at (0,1) {1};
        \end{tikzpicture}
        \caption{CDF of $X$}
        \label{fig:cdf-of-X}
    \end{figure}


    \[
        F_X(a) = 
        \begin{cases} 
            0 & \text{if } a < 0 \\
            0.5 & \text{if } 0 \leq a < 1 \\
            1 & \text{if } a \geq 1 
        \end{cases}
    \]

    \begin{enumerate}
        \item \(\lim_{a \to -\infty} F_X(a) = 0\)
        \item \(\lim_{a \to \infty} F_X(a) = 1\)
        \item \(F_X\) is monotonically increasing, i.e., if \(a < b\), \(F_X(a) \leq F_X(b)\)
        \item \(F_X\) is right continuous, i.e., \(\lim_{a \to a^+} F_X(a) = F_X(a)\) (there are no points of discontinuity when approaching from the right side)
    \end{enumerate}

    \textbf{Definition:} \(X\) and \(Y\) are said to have the same distribution if \(D_X(A) = D_Y(A)\) for all \(A \subseteq \mathbb{R}\). (i.e., \(X\) and \(Y\) cannot be distinguished by looking at the probabilities alone.)

    \textbf{Example:}

    Generate the numbers 0 and 1 so that both are equally likely.
    \begin{itemize}
        \item Toss a fair coin.
        \item Pick a number uniformly at random from the interval \([0, 1]\).
    \end{itemize}

    \(Y: [0, 1] \rightarrow \mathbb{R}\)
    \[
        Y(\omega) = 
        \begin{cases} 
            0 & \text{if } 0 < \omega < \frac{1}{2} \\
            1 & \text{if } \frac{1}{2} < \omega < 1 
        \end{cases}
    \]

    We cannot tell \(X\) and \(Y\) apart by looking at probabilities alone.

    \textbf{Fact:} \(D_X = D_Y\) if and only if \(F_X = F_Y\).

    \[
        D_X(A) = 
        \begin{cases} 
            0 & \text{if } 0, 1 \not\in A \\
            0.5 & \text{if } \{0\}, \{1\} \subseteq A \text{ but not } \{0, 1\} \subseteq A \\
            1 & \text{if } \{0, 1\} \subseteq A 
        \end{cases}
    \]

    \(D_X(A) = P(X \in A)\)

    \textbf{Example:} Suppose you roll a fair die.

    Let \(Y: \Omega \rightarrow \mathbb{R}\) be given by \(Y(\omega) = \omega\), where \(\Omega = \{1, 2, 3, 4, 5, 6\}\).

    What is \(F_Y\)?

    Case 1: \(a < 1\)
    \[
        F_Y(a) = 0
    \]

    Case 2: \(1 \leq a < 2\)
    \[
        F_Y(a) = P(Y \leq a) = P(\{1\}) = \frac{1}{6}
    \]

    Case 3: \(2 \leq a < 3\)
    \[
        F_Y(a) = P(Y \leq a) = P(\{1, 2\}) = \frac{2}{6} = \frac{1}{3}
    \]

    Case 4: \(3 \leq a < 4\)
    \[
        F_Y(a) = P(Y \leq a) = P(\{1, 2, 3\}) = \frac{3}{6} = \frac{1}{2}
    \]

    Case 5: \(4 \leq a < 5\)
    \[
        F_Y(a) = P(Y \leq a) = P(\{1, 2, 3, 4\}) = \frac{4}{6} = \frac{2}{3}
    \]

    Case 6: \(5 \leq a < 6\)
    \[
        F_Y(a) = P(Y \leq a) = P(\{1, 2, 3, 4, 5\}) = \frac{5}{6}
    \]

    Case 7: \(a \geq 6\)
    \[
        F_Y(a) = P(Y \leq a) = P(\{1, 2, 3, 4, 5, 6\}) = 1
    \]


    \section*{Lecture 9: Tuesday 9/24/2024}

    \section*{Probability Distributions and Random Variables}

    \subsection*{Discrete Random Variables}

    The \textbf{Cumulative Distribution Function} (CDF) for a random variable \(X\) is defined as:

    \[F_X(a) = P(X \leq a) = P(X \in (-\infty, a])\]

    Properties of CDF:
    \begin{enumerate}
        \item \(F_X\) is non-decreasing
        \item \(\lim_{x \to -\infty} F_X(x) = 0\) and \(\lim_{x \to \infty} F_X(x) = 1\)
        \item $F_X$ is right-continuous
    \end{enumerate}

    \textbf{Example: Fair Coin Toss}

    Let $X$ be a random variable representing the outcome of a fair coin toss, where 0 represents tails and 1 represents heads.

    The CDF for this scenario is:

    \[
        F_X(a) = 
        \begin{cases} 
            0 & \text{if } a < 0 \\
            \frac{1}{2} & \text{if } 0 \leq a < 1 \\
            1 & \text{if } a \geq 1 
        \end{cases}
    \]

    \textbf{Example: Fair Die Roll}

    Let $X$ be a random variable representing the outcome of rolling a fair six-sided die.

    Sample space: $\Omega = \{1, 2, 3, 4, 5, 6\}$

    The random variable $X$ is defined as: $X(\omega) = \omega$ for $\omega \in \Omega$

    The CDF for $X$ is:

    \[
        F_X(a) = 
        \begin{cases} 
            0 & \text{if } a < 1 \\
            \frac{1}{6} & \text{if } 1 \leq a < 2 \\
            \frac{1}{3} & \text{if } 2 \leq a < 3 \\
            \frac{1}{2} & \text{if } 3 \leq a < 4 \\
            \frac{2}{3} & \text{if } 4 \leq a < 5 \\
            \frac{5}{6} & \text{if } 5 \leq a < 6 \\
            1 & \text{if } a \geq 6 
        \end{cases}
    \]

    Note: If $X$ and $Y$ are random variables, then their distributions $D_X$ and $D_Y$ are equal if and only if their CDFs are equal, i.e., $F_X = F_Y$.

    \pagebreak

    \textbf{Example: Uniform Distribution on $[0, 1]$}

    Let $X$ be a random variable representing a number picked uniformly at random from the interval $[0, 1]$.

    
    We define $X: [0, 1] \to \mathbb{R}$ as $X(\omega) = \omega$ for $\omega \in [0, 1]$.

    To find the cumulative distribution function (CDF) of $X$, we calculate $P(X \leq a)$ for any real number $a$:

    \[
    P(X \leq a) = P(X \in (-\infty, a]) = P(\{\omega \mid X(\omega) \in (-\infty, a]\})
    \]

    We consider three cases:

    \begin{enumerate}
        \item If $a < 0$: $P(X \leq a) = 0$, since $X \in [0, 1]$.
        \item If $0 \leq a \leq 1$: $P(X \leq a) = P(\{\omega \mid X(\omega) \in [0, a]\}) = a$, 
              due to the uniform distribution on $[0, 1]$.
        \item If $a > 1$: $P(X \leq a) = 1$, since $X \leq 1$ always.
    \end{enumerate}

    Therefore, the CDF of $X$ is:

    \[
    F_X(a) = 
    \begin{cases} 
        0, & a < 0 \\
        a, & 0 \leq a \leq 1 \\
        1, & a \geq 1
    \end{cases}
    \]

    This piecewise function represents the uniform distribution on $[0, 1]$.

    \begin{figure}[h]
        \centering
        \begin{tikzpicture}[scale=1.5]
            % Draw the number line
            \draw[-, thick] (-1,0) -- (2,0);
            
            % Draw tick marks and labels
            \foreach \x/\label in {0/0, 1/1} {
                \draw (\x,0.1) -- (\x,-0.1) node[below] {$\label$};
            }
            
            % Highlight the interval [0, 1]
            \draw[thick, red] (0,0.2) -- (1,0.2);
            \node[above, red] at (0.5,0.2) {$[0, 1]$};
            
            % Add a label for a
            \node[below] at (0.7,-0.1) {$a$};
            \draw[dashed] (0.7,0) -- (0.7,-0.1);
        \end{tikzpicture}
        \caption{Number line showing $a$ between 0 and 1 for Uniform Distribution}
        \label{fig:number_line_uniform}
    \end{figure}

    \begin{figure}[h]
        \centering
        \begin{tikzpicture}[scale=4]
            \draw[->] (-0.2,0) -- (1.2,0) node[right] {$a$};
            \draw[->] (0,-0.1) -- (0,1.2) node[above] {$F_X(a)$};
            
            \draw[thick] (0,0) -- (0,0);
            \draw[thick, blue] (0,0) -- (1,1);
            \draw[thick] (1,1) -- (1.2,1);
            
            \foreach \x/\y in {0/0, 1/1}
                \filldraw (\x,\y) circle (0.5pt);
            
            \node[below left] at (0,0) {0};
            \node[below] at (1,0) {1};
            \node[left] at (0,1) {1};
        \end{tikzpicture}
        \caption{CDF of Uniform Distribution on $[0, 1]$}
        \label{fig:cdf_uniform}
    \end{figure}

    \pagebreak

    
    \subsection*{Discrete Random Variables}

    A discrete random variable $X$ is one that takes countably many values. This means it is either finite or can be put into a sequence (countably infinite).

    \textbf{Note:} Countably many values refers to outputs, not inputs.

    \textbf{Examples:}
    \begin{itemize}
        \item Die roll: $X = \{1, 2, 3, 4, 5, 6\}$
        \item Coin toss: $X = \{H, T\}$
    \end{itemize}

    A discrete random variable comes with a \textbf{probability mass function} (PMF or pmf):

    \[
    P_X(x) = P(X = x)
    \]

    \textbf{Example: Fair coin toss}
    \[
    X(H) = 1, \quad X(T) = 0
    \]
    \[
    P_X(x) = 
    \begin{cases} 
        0.5 & \text{if } x = 0 \text{ or } x = 1 \\
        0   & \text{otherwise}
    \end{cases}
    \]

    \textbf{Example: Fair die roll}
    \[
    X = \{1, 2, 3, 4, 5, 6\}
    \]
    \[
    P_X(x) = 
    \begin{cases} 
        \frac{1}{6} & \text{if } x \in \{1, 2, 3, 4, 5, 6\} \\
        0           & \text{otherwise}
    \end{cases}
    \]

    Probabilities for a discrete random variable can be computed as sums of the pmf:

    \[
    P(X \in A) = \sum_{x \in A} P_X(x)
    \]

    \textbf{Note:} For all $x$, $P_X(x) \geq 0$

    \textbf{Example: Die roll}
    \begin{align*}
    P(X \in (2, 6)) &= P(\{\omega \mid X(\omega) \in (2, 6)\}) \\
                    &= \sum_{x \in (2, 6)} P_X(x) \quad \text{where } P_X(x) > 0 \\
                    &= P_X(3) + P_X(4) + P_X(5)\\
                    &= \frac{1}{6} + \frac{1}{6} + \frac{1}{6} =  \frac{3}{6} = \frac{1}{2}
    \end{align*}

    \textbf{Important properties of PMF:}
    \begin{itemize}
        \item $P_X(x) \geq 0$ for all $x$
        \item $\sum_{x \in (-\infty, \infty)} P_X(x) = 1$, where the sum is taken over all $x$ such that $P_X(x) > 0$
    \end{itemize}

    \textbf{Properties of Discrete Random Variables:}
    
    Suppose $X$ and $Y$ are discrete random variables. Then:
    
    \begin{itemize}
        \item $D_X = D_Y$ if and only if $F_X = F_Y$ if and only if $P_X(x) = P_Y(x)$ for all $x \in \mathbb{R}$
        \item If the CDF of $X$ is piecewise constant, then $X$ is a discrete random variable
        \item For a discrete random variable $X$, $P_X(x) = F_X(x) - F_X(x^-)$
    \end{itemize}

    \begin{figure}[h]
        \centering
        \begin{tikzpicture}[scale=0.8]
            \draw[->] (-0.5,0) -- (6,0) node[right] {$x$};
            \draw[->] (0,-0.5) -- (0,4) node[above] {$F_X(x)$};
            
            \draw[thick] (0,0) -- (1,0);
            \draw[thick] (1,1) -- (2,1);
            \draw[thick] (2,2) -- (3,2);
            \draw[thick] (3,3) -- (5,3);
            
            \draw (1,0) circle (2pt);
            \draw (2,1) circle (2pt);
            \draw (3,2) circle (2pt);
            
            \filldraw[black] (1,1) circle (2pt);
            \filldraw[black] (2,2) circle (2pt);
            \filldraw[black] (3,3) circle (2pt);
            
            \draw[dashed] (1,0) -- (1,1);
            \draw[dashed] (2,1) -- (2,2);
            \draw[dashed] (3,2) -- (3,3);
            
            \node[below] at (1,-0.2) {$x_1$};
            \node[below] at (2,-0.2) {$x_2$};
            \node[below] at (3,-0.2) {$x_3$};
            
            \node[left] at (0,1) {$F_X(x_1)$};
            \node[left] at (0,2) {$F_X(x_2)$};
            \node[left] at (0,3) {$F_X(x_3)$};
        \end{tikzpicture}
        \caption{Illustration of CDF for a discrete random variable}
    \end{figure}

    \textbf{Note:} $X$ is a point of discontinuity where $x^-$ is the previous point of discontinuity.
    
    \[
    F_X(x^-) = 
    \begin{cases}
        \text{previous point of discontinuity} & \text{if it exists} \\
        0 & \text{otherwise}
    \end{cases}
    \]

    \textbf{Example:} For a fair die roll,
    \[
    P_X(5) = F_X(5) - F_X(4) = \frac{5}{6} - \frac{4}{6} = \frac{1}{6}
    \]

    
    \pagebreak


    \section*{Lecture 10: Thursday 9/26/2024}

    \subsection*{Discrete Random Variables}

    \textbf{Example:} Suppose that you toss a fair coin until you see heads for the first time.

    Let \(X\) be a random variable that counts the number of tosses.

    Explain why \(X\) is a discrete random variable and compute its \textbf{probability mass function} (PMF).

    \(X\) can only take countably many values. 

    \(X\) takes values from the set \(\{*, 1, 2, 3, \ldots\}\).

    This set is countable, therefore \(X\) is discrete.

    Note: The asterisk (*) is used to denote all tails.

    \[
        P(X = n) = \frac{1}{2^n}
    \]

    \[
        P_X(n) = 
        \begin{cases} 
            \frac{1}{2^n} & \text{if } n \in \{1, 2, 3, \ldots\} \\
            0 & \text{otherwise}
        \end{cases}
    \]

    \begin{figure}[h]
        \centering
        \begin{tikzpicture}[scale=3]
            \draw[->] (-0.2,0) -- (5.2,0) node[right] {$a$};
            \draw[->] (0,-0.1) -- (0,1.2) node[above] {$F_X(a)$};
            
            \draw[thick] (0,0) -- (1,0);
            \draw[thick] (1,0.5) -- (2,0.5);
            \draw[thick] (2,0.75) -- (3,0.75);
            \draw[thick] (3,0.875) -- (4,0.875);
            \draw[thick] (4,0.9375) -- (5,0.9375);
            
            \draw[dashed] (1,0) -- (1,0.5);
            \draw[dashed] (2,0) -- (2,0.75);
            \draw[dashed] (3,0) -- (3,0.875);
            \draw[dashed] (4,0) -- (4,0.9375);
            
            \foreach \x/\y in {1/0, 2/0.5, 3/0.75, 4/0.875}
                \draw (\x,\y) circle (0.7pt);
            
            \foreach \x/\y in {1/0.5, 2/0.75, 3/0.875, 4/0.9375}
                \filldraw (\x,\y) circle (0.7pt);
            
            \foreach \x/\y/\label in {1/0.5/\frac{1}{2}, 2/0.75/\frac{3}{4}, 3/0.875/\frac{7}{8}, 4/0.9375/\frac{15}{16}}
                \node[above right, font=\footnotesize] at (\x,\y) {$(\x,\label)$};
            
            \foreach \x in {1,2,3,4}
                \node[below, font=\footnotesize] at (\x,-0.05) {\x};
            
            \foreach \y/\label in {0.5/\frac{1}{2}, 1/1}
                \node[left, font=\footnotesize] at (-0.1,\y) {$\label$};
        \end{tikzpicture}
        \caption{CDF of X}
        \label{fig:cdf_of_X}
    \end{figure}
    \subsubsection*{CDF of \(X\)}

    \[
        F_X(a) = 
        \begin{cases} 
            0 & \text{if } a < 1 \\
            \frac{1}{2} & \text{if } 1 \leq a < 2 \\
            \frac{3}{4} & \text{if } 2 \leq a < 3 \\
            \frac{7}{8} & \text{if } 3 \leq a < 4 \\
            \frac{15}{16} & \text{if } 4 \leq a < 5 \\
            \vdots & \\
        \end{cases}
    \]

    Recall, \(\lim_{a \to \infty} F_X(a) = 1\).

    \subsection*{Continuous Random Variables}

    A random variable \(X\) is said to be (absolutely) continuous if there exists a function \(f_X\) such that 

    \[
        f_X(x) \geq 0 \quad \text{and} \quad P(a \leq X \leq b) = \int_a^b f_X(x) \, dx
    \]

    \(f_X(x)\) is called the \textbf{probability density function} (PDF) of \(X\).

    Note: The definition of continuous random variables is a little bit broader. We say a random variable \(X\) is continuous if its cdf is continuous. But we will not encounter them in this course, so we take absolutely continuous random variables to mean continuous random variables.

    \subsubsection*{Example}

    Suppose that \(X\) is a continuous random variable with a pdf 

    \[
        f_X(x) =
        \begin{cases} 
            1 & \text{if } x \in [0, 1] \\
            0 & \text{otherwise}
        \end{cases}
    \]

    \begin{enumerate}
        \item Verify that \(f_X(x)\) is a pdf.
        \item Compute \(P\left(\frac{1}{2} < X < \frac{3}{4}\right)\).
        \item Compute \(P\left(X > \frac{3}{4} \mid X > \frac{1}{2}\right)\).
        \item Compute the cdf of \(X\).
    \end{enumerate}




    \subsubsection*{Solution}

    1) A pdf has to satisfy the following properties:
    \begin{itemize}
        \item \(f_X(x) \geq 0\)
        \item \(\int_{- \infty}^{\infty} f_X(x) \, dx = 1\)
    \end{itemize}

    For the given pdf:
    \[
        f_X(x) =
        \begin{cases} 
            1 & \text{if } x \in [0, 1] \\
            0 & \text{otherwise}
        \end{cases}
    \]

    \begin{center}
        \begin{tikzpicture}
            \draw[->] (-0.5,0) -- (1.5,0) node[right] {$x$};
            \draw[->] (0,-0.5) -- (0,1.5) node[above] {$f_X(x)$};
            \draw[thick] (0,1) -- (1,1);
            \draw[dashed] (0,0) -- (0,1);
            \draw[dashed] (1,0) -- (1,1);
            \filldraw[fill=black] (0,1) circle (1.5pt);
            \filldraw[fill=black] (1,1) circle (1.5pt);
            \filldraw[fill=white] (0,0) circle (1.5pt);
            \filldraw[fill=white] (1,0) circle (1.5pt);
            \node[below] at (1,0) {1};
            \node[left] at (0,1) {1};
            \node[below] at (1.5,0) {$x$};
            \node[below left] at (0,0) {0};
        \end{tikzpicture}
    \end{center}

    \[
        \int_{- \infty}^{0} f_X(x) \, dx = 0
    \]
    \[
        \int_{0}^{1} f_X(x) \, dx = 1
    \]
    \[
        \int_{1}^{\infty} f_X(x) \, dx = 0
    \]

    Therefore:
    \[
        \int_{- \infty}^{\infty} f_X(x) \, dx = 1
    \]

    2) Compute \(P\left(\frac{1}{2} < X < \frac{3}{4}\right)\):

    \textbf{Things to notice:} Suppose \(Y\) is a continuous random variable with pdf \(f_Y(y)\). Then for any \(a \in \mathbb{R}\), \(P(Y=a) = 0\).

    \[
        P(Y=a) = P(a \leq Y \leq a) = \int_a^a f_Y(y) \, dy = 0
    \]

    \textbf{Note:}
    \begin{itemize}
        \item ``Possible but not probable'': $P(X = \frac{1}{2}) = 0$
        \item ``Impossible'': $P(X = -3) = 0$
    \end{itemize}



    For our problem:
    \[
        P\left(\frac{1}{2} < X < \frac{3}{4}\right) = \int_{\frac{1}{2}}^{\frac{3}{4}} f_X(x) \, dx
    \]
    \[
        P\left(\frac{1}{2} < X < \frac{3}{4}\right) = \int_{\frac{1}{2}}^{\frac{3}{4}} 1 \, dx = \left. x \right|_{\frac{1}{2}}^{\frac{3}{4}} = \frac{3}{4} - \frac{1}{2} = \frac{1}{4}
    \]

    \begin{center}
        \begin{tikzpicture}
            \draw[->] (-0.5,0) -- (1.5,0) node[right] {$x$};
            \draw[->] (0,-0.5) -- (0,1.5) node[above] {$f_X(x)$};
            \draw[thick] (0,0) -- (0,1) -- (1,1) -- (1,0);
            \fill[gray, opacity=0.5] (0.5,0) rectangle (0.75,1);
            \node at (0.5,-0.3) {$\frac{1}{2}$};
            \node at (0.75,-0.3) {$\frac{3}{4}$};
            \node at (-0.2,1) {1};
        \end{tikzpicture}
    \end{center}

    3) Compute \(P\left(X > \frac{3}{4} \mid X > \frac{1}{2}\right)\):
    
    \begin{center}
        \begin{tikzpicture}
            % Axes
            \draw[->] (-0.2,0) -- (1.2,0) node[right] {$x$};
            \draw[->] (0,-0.2) -- (0,1.2) node[above] {$f_X(x)$};
            
            % PDF
            \draw[thick] (0,0) -- (0,1) -- (1,1) -- (1,0);
            
            % Shaded area for P(X > 3/4 | X > 1/2)
            \fill[gray, opacity=0.3] (0.75,0) rectangle (1,1);
            
            % Vertical lines
            \draw[dashed] (0.5,0) -- (0.5,1);
            \draw[dashed] (0.75,0) -- (0.75,1);
            
            % Labels
            \node[below] at (0.5,0) {$\frac{1}{2}$};
            \node[below] at (0.75,0) {$\frac{3}{4}$};
            \node[left] at (0,1) {1};
        \end{tikzpicture}
    \end{center}
    
    \[
        P\left(X > \frac{3}{4} \mid X > \frac{1}{2}\right) = \frac{P\left(X > \frac{3}{4} \cap X > \frac{1}{2}\right)}{P\left(X > \frac{1}{2}\right)}
    \]
    \[
        P\left(X > \frac{3}{4}\right) = \int_{\frac{3}{4}}^{1} 1 \, dx = 1 - \frac{3}{4} = \frac{1}{4}
    \]
    \[
        P\left(X > \frac{1}{2}\right) = \int_{\frac{1}{2}}^{1} 1 \, dx = 1 - \frac{1}{2} = \frac{1}{2}
    \]
    \[
        P\left(X > \frac{3}{4} \mid X > \frac{1}{2}\right) = \frac{\frac{1}{4}}{\frac{1}{2}} = \frac{1}{2}
    \]

    4) Compute the cdf of \(X\):

    \[
        F_X(a) = P(x \leq a) = \int_{- \infty}^{a} f_X(x) \, dx
    \]

    Case 1: \(a < 0\)
    \[
        F_X(a) = \int_{- \infty}^{a} 0 \, dx = 0
    \]


    \[
        F_X(a) = 
        \begin{cases} 
            0 & \text{if } a < 0 \\
            a & \text{if } 0 \leq a < 1 \\
            1 & \text{if } a \geq 1 
        \end{cases}
    \]
    \begin{center}
        \begin{tikzpicture}
            \begin{scope}[xshift=-3cm]
                \draw[->] (-0.5,0) -- (1.5,0) node[right] {$x$};
                \draw[->] (0,-0.5) -- (0,1.5) node[above] {$f_X(x)$};
                
                % Draw the PDF
                \draw[thick, red] (0,1) -- (1,1);
                \draw[thick, red] (-0.5,0) -- (0,0);
                \draw[thick, red] (1,1) -- (1,0);
                \draw[thick, red] (1,0) -- (1.5,0);
                
                % Add labels
                \node at (1,-0.2) {1};
                \node at (-0.2,1) {1};
                \node[below left] at (0,0) {0};
                
                % Title
                \node[above] at (0.5,2.5) {PDF of $X$};
            \end{scope}
            
            \begin{scope}[xshift=3cm]
                \draw[->] (-0.5,0) -- (1.5,0) node[right] {$x$};
                \draw[->] (0,-0.5) -- (0,1.5) node[above] {$F_X(x)$};
                
                % Draw the CDF
                \draw[thick, blue] (-0.5,0) -- (0,0);
                \draw[thick, blue] (0,0) -- (1,1);
                \draw[thick, blue] (1,1) -- (1.5,1);
                
                % Add labels and gridlines
                \draw[dashed] (1,0) -- (1,1);
                \draw[dashed] (0,1) -- (1,1);
                \node at (1,-0.2) {1};
                \node at (-0.2,1) {1};
                
                % Add labels for each part of the function
                \node[below left] at (0,0) {0};
                \node[above] at (0.5,0.5) {$x$};
                \node[right] at (1.25,1) {1};
                
                % Title
                \node[above] at (0.5,2.5) {CDF of $X$};
            \end{scope}
        \end{tikzpicture}
    \end{center}

    \textbf{Facts:} Let \(X\) and \(Y\) be two continuous random variables with pdfs \(f_X(x)\) and \(f_Y(y)\). Then:
    \[
        D_X = D_Y \text{ if and only if } F_X = F_Y \text{ if and only if } f_X(x) = f_Y(y) \text{ almost everywhere.}
    \]

    \textbf{Example:} Suppose \(X\) is a continuous random variable with pdf:
    \[
        f_X(x) = 
        \begin{cases} 
            e^{-x} & \text{if } x \geq 0 \\
            0 & \text{otherwise}
        \end{cases}
    \]

    Compute \(P(X > \frac{1}{2})\):
    \begin{align*}
        P(X > \frac{1}{2}) &= \int_{\frac{1}{2}}^{\infty} e^{-x} \, dx \\
        &= \lim_{b \to \infty} \int_{\frac{1}{2}}^{b} e^{-x} \, dx \\
        &= \lim_{b \to \infty} \left[ -e^{-x} \right]_{\frac{1}{2}}^{b} \\
        &= \lim_{b \to \infty} \left[ (-e^{-b}) - (-e^{-\frac{1}{2}}) \right] \\
        &= \lim_{b \to \infty} \left[ -e^{-b} + e^{-\frac{1}{2}} \right] \\
        &= 0 + e^{-\frac{1}{2}} \\
        &= e^{-\frac{1}{2}} \\
        &= \frac{1}{\sqrt{e}}
    \end{align*}

    \begin{center}
        \begin{tikzpicture}[scale=1.5]
            \draw[->] (-0.5,0) -- (4.5,0) node[right] {$x$};
            \draw[->] (0,-0.1) -- (0,1.2) node[above] {$f_X(x)$};
            
            % Draw the exponential function
            \draw[thick, blue, domain=0:4, smooth, variable=\x] plot ({\x},{exp(-\x)});
            
            % Add labels and gridlines
            \draw[dashed] (0,1) -- (4,1);
            \node at (-0.2,1) {1};
            \node at (1,-0.2) {1};
            \node at (2,-0.2) {2};
            \node at (3,-0.2) {3};
            
            % Label the function
            \node[right] at (4,0.2) {$e^{-x}$};
            
            % Title
            \node[above] at (2,1.5) {PDF of $X$: $f_X(x) = e^{-x}$ for $x \geq 0$};
        \end{tikzpicture}
    \end{center}
    Compute the cdf of \(X\):
    \begin{align*}
        F_X(a) &= P(X \leq a) \\
               &= \int_{-\infty}^a f_X(t) \, dt \\
               &= \begin{cases} 
                    0 & \text{if } a < 0 \\
                    \int_0^a e^{-t} \, dt & \text{if } a \geq 0 
                  \end{cases} \\
               &= \begin{cases} 
                    0 & \text{if } a < 0 \\
                    [-e^{-t}]_0^a & \text{if } a \geq 0 
                  \end{cases} \\
               &= \begin{cases} 
                    0 & \text{if } a < 0 \\
                    -e^{-a} - (-e^0) = 1 - e^{-a} & \text{if } a \geq 0 
                  \end{cases}
    \end{align*}

    Therefore, the cdf of \(X\) is:
    \[
        F_X(a) = 
        \begin{cases} 
            0 & \text{if } a < 0 \\
            1 - e^{-a} & \text{if } a \geq 0 
        \end{cases}
    \]

    \begin{center}
        \begin{tikzpicture}[scale=1.5]
            \draw[->] (-1,0) -- (4.5,0) node[right] {$a$};
            \draw[->] (0,-0.1) -- (0,1.2) node[above] {$F_X(a)$};
            
            % Draw the CDF
            \draw[thick] (-1,0) -- (0,0);
            \draw[thick, blue, domain=0:4, smooth, variable=\a] plot ({\a},{1 - exp(-\a)});
            
            % Add labels and gridlines
            \draw[dashed] (0,1) -- (4,1);
            \node at (-0.2,1) {1};
            \node at (1,-0.2) {1};
            \node at (2,-0.2) {2};
            \node at (3,-0.2) {3};
            
            % Label the function
            \node[right] at (4,0.98) {$1 - e^{-a}$};
            
            % Title
            \node[above] at (2,1.5) {CDF of $X$: $F_X(a) = 1 - e^{-a}$ for $a \geq 0$};
        \end{tikzpicture}
    \end{center}

    \textbf{Properties of CDF:}
    \begin{enumerate}
        \item Limits:
        \[
            \lim_{a \to -\infty} F_X(a) = 0
        \]
        \[
            \lim_{a \to \infty} F_X(a) = 1
        \]
        \item Right-continuity:
        \[
            \lim_{a \to x^+} F_X(a) = F_X(x)
        \]
        \item Monotonicity:
        \[
            \text{If } a < b, \text{ then } F_X(a) \leq F_X(b)
        \]
    \end{enumerate}

    \textbf{Probability calculations using CDF:}
    \begin{align*}
        P(X \leq a) &= F_X(a) \\
        P(X > a) &= 1 - F_X(a) \\
        P(a < X \leq b) &= F_X(b) - F_X(a)
    \end{align*}

    \textbf{Example:} For our exponential distribution with $F_X(a) = 1 - e^{-a}$ for $a \geq 0$:
    \begin{align*}
        P(X > \frac{1}{2}) &= 1 - P(X \leq \frac{1}{2}) = 1 - F_X(\frac{1}{2}) \\
        &= 1 - (1 - e^{-\frac{1}{2}}) = e^{-\frac{1}{2}}
    \end{align*}

    \begin{align*}
        P(\frac{1}{2} < X < 10) &= F_X(10) - F_X(\frac{1}{2}) \\
        &= (1 - e^{-10}) - (1 - e^{-\frac{1}{2}}) \\
        &= e^{-\frac{1}{2}} - e^{-10}
    \end{align*}

    \textbf{Fact:} If $F_X$ is differentiable, with possibly finitely many exceptions, then
    \[
        F'_X(x) = f_X(x) \quad \text{(except where $F_X$ is not differentiable)}
    \]

    \subsection*{Expected Value}

    The expected value of a random variable X, denoted as E(X), is defined as:

    \[
    E(X) = 
    \begin{cases} 
        \sum_{i} x_i P(X = x_i) & \text{if X is discrete} \\
        \int_{-\infty}^{\infty} x f_X(x) \, dx & \text{if X is continuous}
    \end{cases}
    \]

    \textbf{Properties of Expected Value:}
    \begin{itemize}
        \item E(X) is a ``weighted sum'' or ``weighted average'' of possible values of X.
        \item E(X) provides a single value summary of the random variable X.
        \item E(X) represents the long-run average of the random variable over many trials.
    \end{itemize}

    \subsection*{Important Inequalities}

    \textbf{Markov's Inequality:}
    For a non-negative random variable X and any positive number a,
    \[
    P(X \geq a) \leq \frac{E(X)}{a}
    \]

    \textbf{Chebyshev's Inequality:}
    For any random variable X with finite expected value $\mu$ and finite non-zero variance $\sigma^2$,
    \[
    P(|X - \mu| \geq k\sigma) \leq \frac{1}{k^2}
    \]

    \subsection*{Law of Large Numbers}

    \textbf{Strong Law of Large Numbers (SLLN):} 
    If we generate a large number of independent and identically distributed random variables $X_1, \ldots, X_n$, and compute their average, then this average will converge to the expected value E(X) as n approaches infinity:

    \[
    \frac{1}{n}\sum_{i=1}^{n} X_i \approx E(X)
    \]

    This law provides a theoretical foundation for the empirical average to approximate the expected value for a large number of trials.

    
    \pagebreak

    \section*{Lecture 11: Tuesday 10/1/2024}

    \subsection*{Expected Value}

    The expected value of a random variable X, denoted as E(X), is defined as:

    \[
    E(X) = 
    \begin{cases} 
        \sum_{i} x_i P(X = x_i) & \text{if X is discrete} \\
        \int_{-\infty}^{\infty} x f_X(x) \, dx & \text{if X is continuous}
    \end{cases}
    \]

    \textbf{Properties of Expected Value:}
    \begin{itemize}
        \item E(X) is a ``weighted sum''
        \item E(X) provides a single value summary of the random variable X
        \item E(X) represents the long-run average of the random variable over many trials
    \end{itemize}

    \subsection*{Important Inequalities}

    \begin{itemize}
        \item \textbf{Markov's Inequality}
        \item \textbf{Chebyshev's Inequality}
    \end{itemize}

    \subsection*{Strong Law of Large Numbers (SLLN)}
    
    Suppose that you repeat the experiment associated with X in an independent manner and write out
    the measurements obtained as $X_1, X_2, \ldots, X_n$.
    
    For large n, the average approximates the expected value:
    
    \[
    \frac{1}{n}\sum_{i=1}^{n} X_i \approx E(X)
    \]

    \subsection*{Example: Rolling a Fair Die}

    Let X($\omega$) = $\omega$ report the outcome of the die roll.

    \textbf{Probability Mass Function:}
    \[
    P_X(x) = 
    \begin{cases}
        \frac{1}{6} & \text{if } x = 1, 2, 3, 4, 5, 6 \\
        0 & \text{otherwise}
    \end{cases}
    \]

    \textbf{Expected Value Calculation:}
    \begin{align*}
        E(X) &= \sum_{i=1}^{6} i P_X(i) \\
             &= 1 \cdot \frac{1}{6} + 2 \cdot \frac{1}{6} + 3 \cdot \frac{1}{6} + 4 \cdot \frac{1}{6} + 5 \cdot \frac{1}{6} + 6 \cdot \frac{1}{6} \\
             &= \frac{1}{6}(1 + 2 + 3 + 4 + 5 + 6) \\
             &= \frac{1}{6}(\frac{6 \cdot 7}{2}) \\
             &= \frac{7}{2} = 3.5
    \end{align*}

    \textbf{Experiment:}
    \begin{itemize}
        \item Roll the die n = 10000 times and record the outcomes.
        \item Compute the average of the outcomes.
        \item Notice that the average $\frac{1}{n}\sum_{i=1}^{n} X_i$ is close to 3.5.
    \end{itemize}

    \textbf{Example:} Suppose $X$ is a continuous random variable with cumulative distribution function:
    \[
    F_X(x) = 
    \begin{cases}
        e^{-x} & \text{for } x \geq 0 \\
        0 & \text{otherwise}
    \end{cases}
    \]

    Find $E(X)$.

    \begin{align*}
        E(X) &= \int_{-\infty}^{\infty} x f_X(x) \, dx \\
             &= \int_{0}^{\infty} x e^{-x} \, dx \quad \text{(since $f_X(x) = 0$ for $x < 0$)} \\
             &= \lim_{b \to \infty} \int_{0}^{b} x e^{-x} \, dx
    \end{align*}

    To solve this integral, we use integration by parts:
    \begin{itemize}
        \item Let $u = x$ and $dv = e^{-x} \, dx$
        \item Then $du = dx$ and $v = -e^{-x}$
    \end{itemize}

    Applying integration by parts:
    \begin{align*}
        E(X) &= \lim_{b \to \infty} \left[ -x e^{-x} \bigg|_{0}^{b} + \int_{0}^{b} e^{-x} \, dx \right] \\
             &= \lim_{b \to \infty} \left[ (-b e^{-b} - (-0 \cdot e^{0})) + \left( -e^{-x} \bigg|_{0}^{b} \right) \right] \\
             &= \lim_{b \to \infty} \left[ -b e^{-b} + \left( -e^{-b} - (-e^{0}) \right) \right] \\
             &= \lim_{b \to \infty} \left[ -b e^{-b} - e^{-b} + 1 \right] \\
             &= 1 - \lim_{b \to \infty} (b e^{-b} + e^{-b}) \\
             &= 1 - 0 - 0 \quad \text{(since $\lim_{b \to \infty} b e^{-b} = \lim_{b \to \infty} e^{-b} = 0$)} \\
             &= 1
    \end{align*}

    Therefore, $E(X) = 1$.


    % \begin{figure}[h]
    %     \centering
    %     \begin{tikzpicture}
    %         % Define the axes
    %         \draw[->] (0,0) -- (5,0) node[right] {$x$};
    %         \draw[->] (0,0) -- (0,3) node[above] {$f_X(x)$};
            
    %         % Plot the exponential function
    %         \draw[domain=0:5, smooth, variable=\x, blue, thick] plot ({\x}, {e^(-\x)});
            
    %         % Label the function
    %         \node[above] at (4,0.2) {$f_X(x) = e^{-x}$};
            
    %         % Add labels for key points
    %         \node[below left] at (0,0) {0};
    %         \node[left] at (0,1) {1};
    %         \node[below] at (1,0) {1};
    %     \end{tikzpicture}
    %     \caption{Probability Density Function of $X$: $f_X(x) = e^{-x}$ for $x \geq 0$}
    %     \label{fig:exponential_pdf}
    % \end{figure}


    \subsection*{Law of the Unconscious Statistician (LOTUS)}

    Let $g : \mathbb{R} \to \mathbb{R}$ be a real-valued function of the random variable $X$. Then:

    \[
    E[g(X)] = 
    \begin{cases} 
        \sum_{x} g(x) P_X(x) & \text{if $X$ is discrete} \\[2ex]
        \int_{-\infty}^{\infty} g(x) f_X(x) \, dx & \text{if $X$ is continuous}
    \end{cases}
    \]

    \noindent
    \textbf{Note:} $E[g(X)] = E[Z]$ where $Z = g(X)$. However, computing $E[Z]$ directly as
    \[
    E[Z] = \int_{-\infty}^{\infty} z f_Z(z) \, dz
    \]
    can be challenging and is often unnecessary due to LOTUS.

    \vspace{1em}

    \noindent
    \textbf{Example:} Suppose $X$ is a discrete random variable with PMF:
    
    \[
    P_X(x) = 
    \begin{cases}
        \frac{1}{3} & \text{if } x = -1, 0, 1 \\
        0 & \text{otherwise}
    \end{cases}
    \]

    \noindent
    What is the PMF of $Y = X^2$?

    \vspace{0.5em}

    \noindent
    \textbf{Solution:}
    \[
    P_Y(y) = 
    \begin{cases}
        \frac{1}{3} & \text{if } y = 0 \\
        \frac{2}{3} & \text{if } y = 1 \\
        0 & \text{otherwise}
    \end{cases}
    \]

    \noindent
    \textbf{Using the definition:}
    \begin{align*}
        E(X^2) &= \sum_{y = 0}^{1} y P_Y(y) \\
               &= 0 \cdot \frac{1}{3} + 1 \cdot \frac{2}{3} = \frac{2}{3}
    \end{align*}

    \noindent
    \textbf{Using LOTUS:}
    \begin{align*}
        E(X^2) &= \sum_{x = -1}^{1} x^2 P_X(x) \\
               &= (-1)^2 \cdot \frac{1}{3} + 0^2 \cdot \frac{1}{3} + 1^2 \cdot \frac{1}{3} = \frac{2}{3}
    \end{align*}

    \vspace{1em}
    \noindent
    \textbf{Fact:} For constants $a$ and $b$,
    \[
        E(aX + b) = aE(X) + b
    \]

    \vspace{0.5em}
    \noindent
    Suppose $X$ is a continuous random variable with PDF $f_X(x)$.

    \vspace{0.5em}
    \noindent
    \textbf{Proof using LOTUS:}
    \begin{align*}
        E(aX + b) &= \int_{-\infty}^{\infty} (ax + b)f_X(x)\,dx \\
                  &= a\int_{-\infty}^{\infty} xf_X(x)\,dx + b\int_{-\infty}^{\infty} f_X(x)\,dx \\
                  &= aE(X) + b \cdot 1 \\
                  &= aE(X) + b
    \end{align*}




    \subsection*{Variance}

    Variance measures the spread of observations around the mean of a random variable.

    For a random variable $X$ with mean $\mu = E(X)$, the variance is defined as:
    \[
    V(X) = E((X - \mu)^2)
    \]

    For any random variable $X$, the variance can be computed as:
    \[
    V(X) = E(X^2) - (E(X))^2
    \]

    \noindent
    \textbf{Proof:}
    Let $X$ be a continuous random variable with probability density function $f_X(x)$ and mean $\mu = E(X)$.
    Using the Law of the Unconscious Statistician (LOTUS):
    \begin{align*}
        V(X) &= E((X - \mu)^2) \\
             &= \int_{-\infty}^{\infty} (x - \mu)^2 f_X(x) \, dx \\
             &= \int_{-\infty}^{\infty} (x^2 - 2\mu x + \mu^2) f_X(x) \, dx \\
             &= \int_{-\infty}^{\infty} x^2 f_X(x) \, dx - 2\mu \int_{-\infty}^{\infty} x f_X(x) \, dx + \mu^2 \int_{-\infty}^{\infty} f_X(x) \, dx \\
             &= E(X^2) - 2\mu E(X) + \mu^2 \\
             &= E(X^2) - 2\mu^2 + \mu^2 \\
             &= E(X^2) - \mu^2 \\
             &= E(X^2) - (E(X))^2
    \end{align*}

    \noindent
    \textbf{Note:} The proof for discrete random variables follows a similar structure, replacing integrals with sums.

    \subsection*{Visualization of Low and High Variance}

    To illustrate the concept of low and high variance, consider two normal distributions:

    \begin{figure}[h]
        \centering
        \begin{tikzpicture}
            \begin{axis}[
                width=12cm,
                height=6cm,
                xlabel=$x$,
                ylabel=Probability Density,
                ymin=0,
                xmin=-4,
                xmax=4,
                samples=100,
                smooth,
                domain=-4:4,
                legend pos=north west,
            ]
            \addplot[blue, thick] {1/(0.5*sqrt(2*pi)) * exp(-(x^2)/(2*0.5^2))};
            \addlegendentry{Low Variance }
            \addplot[red, thick] {1/(1.5*sqrt(2*pi)) * exp(-(x^2)/(2*1.5^2))};
            \addlegendentry{High Variance}
            \end{axis}
        \end{tikzpicture}
        \caption{Comparison of normal distributions with low and high variance}
        \label{fig:variance_comparison}
    \end{figure}

    \begin{itemize}
        \item The blue curve represents a distribution with low variance, more concentrated around its mean.
        \item The red curve represents a distribution with high variance, more spread out from its mean.
        \item Both distributions have the same mean (center) but differ in their spread.
    \end{itemize}

    \subsection*{Markov's Inequality}

    For a non-negative random variable $X$ and any positive constant $a$, if $E(X)$ exists and is finite:
    \[
    P(X \geq a) \leq \frac{E(X)}{a}
    \]

    \noindent
    \textbf{Example:}
    Suppose $X$ is a non-negative random variable with $E(X) = 5$. Find upper bounds for:
    \begin{itemize}
        \item $P(X \geq 5)$
        \item $P(X \geq 500)$
    \end{itemize}

    \noindent
    \textbf{Solution:}
    \begin{align*}
        P(X \geq 5) &\leq \frac{E(X)}{5} = \frac{5}{5} = 1 \quad \text{(not a useful bound)} \\
        P(X \geq 500) &\leq \frac{E(X)}{500} = \frac{5}{500} = 0.01
    \end{align*}

    \begin{figure}[h]
        \centering
        \begin{tikzpicture}
            \begin{axis}[
                width=12cm,
                height=8cm,
                xlabel=$a$,
                ylabel={Upper bound on $P(X \geq a)$},
                xmin=0, xmax=500,
                ymin=0, ymax=1.1,
                xtick={0,100,200,300,400,500},
                ytick={0,0.2,0.4,0.6,0.8,1},
                legend pos=north east,
                title={Markov's Inequality Upper Bounds},
                grid=both,
                axis lines=left,
            ]
            \addplot[domain=0.1:500, blue, thick, samples=100] {5/x};
            \addlegendentry{$E(X)=5$}
            
            \draw[dashed, gray] (axis cs:5,0) -- (axis cs:5,1);
            \draw[dashed, gray] (axis cs:10,0) -- (axis cs:10,0.5);
            \draw[dashed, gray] (axis cs:500,0) -- (axis cs:500,0.01);
            
            \node[anchor=north west, text=black, font=\small] at (axis cs:5.2,0.95) {$P(X \geq 5) \leq 1$};
            \node[anchor=north west, text=black, font=\small] at (axis cs:10.2,0.45) {$P(X \geq 10) \leq 0.5$};
            \node[anchor=north west, text=black, font=\small] at (axis cs:505,0.01) {$P(X \geq 500) \leq 0.01$};
        \end{axis}
    \end{tikzpicture}
    \caption{Visualization of Markov's Inequality upper bound for $E(X)=5$, extended to $a=500$}
    \label{fig:markov_inequality_extended}
    \end{figure}

    The graph above illustrates Markov's Inequality for different $E(X)$ values. The curves represent the upper bound $\frac{E(X)}{a}$ as $a$ varies. As $a$ increases, the upper bound decreases, providing tighter bounds for larger values of $a$.

    \subsection*{Chebyshev's Inequality}
    For a random variable $X$ with finite mean $\mu$ and variance $\sigma^2$, and for any positive constant $k$:
   
    \[
    P(|X - \mu| \geq k) \leq \frac{\sigma^2}{k^2}
    \]

    \noindent
    \textbf{Example:} Let $X$ be a random variable with $E(X) = 4$ and $V(X) = 16$. Find an upper bound for $P(|X-4| \geq 1600)$.

    \noindent
    \textbf{Solution:}
    \begin{align*}
        P(|X-4| \geq 1600) &= P(|X-\mu| \geq 1600) \\
                        &\leq \frac{V(X)}{1600^2} \\
                        &= \frac{16}{1600^2} \\
                        &= \frac{1}{10000} \approx 0.0001
    \end{align*}

    Note: $\sigma = \sqrt{V(X)} = 4$, and $k = \frac{1600}{\sigma} = \frac{1600}{4} = 400$

    \subsection*{Strong Law of Large Numbers (SLLN)}

    \noindent
    \textbf{Example:} Approximate $\int_{0}^{1} \sqrt{1-x^2} dx$

    \noindent
    \textbf{Solution:} The exact value of this integral is $\frac{\pi}{4}$.

    \begin{figure}[h]
        \centering
        \begin{tikzpicture}
            \begin{axis}[
                width=5cm,
                height=5cm,
                axis lines=middle,
                xlabel=$x$,
                ylabel=$y$,
                xmin=0, xmax=1.2,
                ymin=0, ymax=1.2,
                xtick={0,0.5,1},
                ytick={0,0.5,1},
            ]
                \addplot[domain=0:1, samples=100, smooth, thick, blue] {sqrt(1-x^2)};
                \addplot[domain=0:1, samples=100, fill=blue!10, draw=none] {sqrt(1-x^2)} \closedcycle;
                \node at (axis cs:0.9,0.9) {$y = \sqrt{1-x^2}$};
            \end{axis}
        \end{tikzpicture}
        \caption{Graph of $y = \sqrt{1-x^2}$ (quarter circle)}
        \label{fig:quarter_circle}
    \end{figure}

    The graph above illustrates the region under the curve $y = \sqrt{1-x^2}$ from $x=0$ to $x=1$, which forms a quarter circle. The area of this region is equal to $\frac{\pi}{4}$, which is the exact value of the integral $\int_{0}^{1} \sqrt{1-x^2} dx$.

    Let $Y$ be a continuous random variable with PDF:
    \[
    f_Y(y) = 
    \begin{cases} 
        1 & 0 \leq y \leq 1 \\
        0 & \text{otherwise}
    \end{cases}
    \]

    Using the Law of the Unconscious Statistician (LOTUS), we can calculate:
    \begin{align*}
    E(\sqrt{1-Y^2}) &= \int_{-\infty}^{\infty} \sqrt{1-y^2} f_Y(y) dy \\
    &= \int_{0}^{1} \sqrt{1-y^2} dy
    \end{align*}

    To evaluate this integral, we can use the substitution $u = 1-y^2$, $du = -2y dy$:
    \begin{align*}
    E(\sqrt{1-Y^2}) &= \int_{0}^{1} \sqrt{1-y^2} dy \\
    &= -\frac{1}{2} \int_{1}^{0} \frac{\sqrt{u}}{\sqrt{1-u}} du \\
    &= \frac{1}{2} \int_{0}^{1} \frac{\sqrt{u}}{\sqrt{1-u}} du \\
    &= \frac{\pi}{4}
    \end{align*}

    The last step involves recognizing this as a standard integral that evaluates to $\frac{\pi}{2}$.

    By the Strong Law of Large Numbers, if we generate independent samples $Y_1, Y_2, \ldots, Y_n$ from the distribution of $Y$, then:
    \[
    \lim_{n \to \infty} \frac{1}{n} \sum_{i=1}^{n} \sqrt{1-Y_i^2} = E(\sqrt{1-Y^2}) = \frac{\pi}{4} \quad \text{(almost surely)}
    \]

    This provides a method to approximate $\frac{\pi}{4}$ using random sampling.

    \pagebreak


    \section*{Lecture 12: Thursday 10/3/2024}

    \subsection*{Special Distributions (Discrete)}

    \begin{itemize}
        \item Bernoulli Distribution
        \item Geometric Distribution
        \item Binomial Distribution
        \item Hypergeometric Distribution
    \end{itemize}

    \subsubsection*{Bernoulli Distribution}

    \begin{itemize}
        \item A Bernoulli trial is an experiment with only two possible outcomes: success (S) or failure (F).
        \item A Bernoulli random variable $X$ is a discrete random variable with probability mass function:
        
        \[
        P_X(x) = 
        \begin{cases} 
            p & \text{if } x = 1 \text{ (success)} \\
            q = 1 - p & \text{if } x = 0 \text{ (failure)}
        \end{cases}
        \]
        
        \item The probability of success is $p$.
        \item We denote this as $X \sim \text{Ber}(p)$.
        \item $p$ is a parameter that keeps track of the probability of success, which may differ between experiments modeled by Bernoulli trials.
    \end{itemize}

    \textbf{Properties:}
    \begin{align*}
        E(X) &= \sum xP_X(x) = 0 \cdot (1-p) + 1 \cdot p = p \\
        V(X) &= E(X^2) - (E(X))^2 = \sum x^2 P_X(x) - p^2 = p - p^2 = p(1-p)
    \end{align*}

    \subsubsection*{Geometric Distribution}

    Consider an experiment where you repeat independent Bernoulli trials until you observe the first success, at which point you stop. Let $X$ be the number of trials needed to see the first success.

    \begin{itemize}
        \item $X$ is a discrete random variable.
        \item Let $p$ be the probability of success for an individual Bernoulli trial, where $0 < p < 1$.
        \item We want to find the probability mass function (PMF) of $X$.
    \end{itemize}

    \textbf{Probability Mass Function:}

    For $k = 1, 2, 3, \ldots$, the PMF of $X$ is given by:

    \[
    P(X = k) = (1-p)^{k-1} p
    \]

    This can be interpreted as:
    \begin{itemize}
        \item $(1-p)^{k-1}$: probability of $k-1$ consecutive failures
        \item $p$: probability of success on the $k$-th trial
    \end{itemize}

    \textbf{Visual Representation:}

    \begin{tikzpicture}[scale=0.8]
        % Tree diagram
        \node (start) at (0,0) {Start};
        \node (f1) at (2,-1) {F};
        \node (s1) at (2,1) {S};
        \node (f2) at (4,-2) {F};
        \node (s2) at (4,0) {S};
        \node (f3) at (6,-3) {F};
        \node (s3) at (6,-1) {S};
        \node (dots) at (8,-4) {$\cdots$};
        \node (sn) at (8,-2) {S};
        
        \draw[->] (start) -- (f1) node[midway,below left] {$1-p$};
        \draw[->] (start) -- (s1) node[midway,above] {$p$};
        \draw[->] (f1) -- (f2) node[midway,below left] {$1-p$};
        \draw[->] (f1) -- (s2) node[midway,above] {$p$};
        \draw[->] (f2) -- (f3) node[midway,below left] {$1-p$};
        \draw[->] (f2) -- (s3) node[midway,above] {$p$};
        \draw[->] (f3) -- (dots) node[midway,below left] {$1-p$};
        \draw[->] (f3) -- (sn) node[midway,above] {$p$};
       
    \end{tikzpicture}

    Where F represents failure and S represents success.

    \textbf{Note:} The geometric distribution models the number of trials until the first success, including the successful trial.

    The probability mass function $P_X(x)$ for the geometric distribution is:

    \[
    P_X(x) = 
    \begin{cases}
        (1-p)^{x-1}p & \text{for } x = 1, 2, 3, \ldots \\
        0 & \text{otherwise}
    \end{cases}
    \]

    where $p$ is the probability of success on each trial.

    We denote this as $X \sim \text{Geom}(p)$

    The expected value is:
    \[
    E(X) = \frac{1}{p}
    \]

    \subsubsection*{Example: Lottery}
    Suppose there is a lottery where the chances of winning are $\frac{1}{10^6}$. What does $X \sim \text{Geom}(\frac{1}{10^6})$ and $E(X) = 10^6$ tell you about this? Say you always buy the ticket with your collection of lucky numbers.

    \begin{itemize}
        \item $X$ represents the number of times the lottery is played until you win.
        \item On average $(E(X))$, you need to play the lottery $10^6$ times to see your first win.
    \end{itemize}
    
    \subsubsection*{Example: Probability Calculation}
    Suppose that $X \sim \text{Geom}(\frac{1}{3})$. What is the probability that $X > 2$ (i.e., $P(X > 2)$)?
    
    \begin{align*}
    P(X > 2) &= 1 - P(X \leq 2) \\
    &= 1 - \sum_{x=1}^{2} \frac{1}{3} \left(\frac{2}{3}\right)^{x-1} \\
    &= 1 - \left[\frac{1}{3} + \frac{1}{3} \cdot \frac{2}{3}\right] \\
    &= 1 - \frac{5}{9} = \frac{4}{9}
    \end{align*}
    
    Note: $p = \frac{1}{3}$ and $1-p = \frac{2}{3}$

    \subsubsection*{Binomial Distribution}

    Suppose that a fixed number of Bernoulli trials $n$, each trial with a probability of success $p$, are conducted in an independent manner. Let $X$ be the total number of successes. $X$ is a discrete random variable and we say that $X \sim \text{Bin}(n, p)$. In other words, $X$ has a binomial distribution with parameters $n$ and $p$.

    Note: $X \sim \text{Bin}(1, p)$ is the same as $X \sim \text{Ber}(p)$.

    To derive $P_X(x)$:

    \begin{itemize}
        \item Consider a sequence: $\underbrace{S \ldots S}_{(k \text{ successes})} \underbrace{F \ldots F}_{(n-k \text{ failures})}$
        \item Probability of this sequence: $p^k(1-p)^{n-k}$
        \item Number of possible rearrangements: $\binom{n}{k}$
    \end{itemize}

    \textbf{Note:} recall that $\binom{n}{k} = \frac{n!}{k!(n-k)!}$

    Therefore, the probability mass function is:

    \[
    P_X(x) = 
    \begin{cases}
        \binom{n}{x} p^x (1-p)^{n-x}, & x = 0, 1, 2, \ldots, n \\
        0, & \text{otherwise}
    \end{cases}
    \]
    
    \textbf{Properties of Binomial Distribution:}
    \begin{align*}
        E(X) &= np \\
        V(X) &= npq \quad \text{where } q = 1-p
    \end{align*}

    Consider a biased coin that comes up heads with a probability of $\frac{1}{4}$. We flip this coin 32 times in succession. Calculate the following:

    \begin{enumerate}
        \item What is the probability we see exactly 12 heads?
        \item What is the probability we see between 7 and 12 heads?
        \item What is the probability we see 20 tails?
        \item What is the average number of heads (expected number of heads)?
    \end{enumerate}

    If we define $X$ as the random variable representing the number of heads observed, then $X$ follows a binomial distribution with parameters $n=32$ and $p=\frac{1}{4}$, i.e., $X \sim \text{Bin}(32, \frac{1}{4})$

    \begin{enumerate}
        \item $P(X = 12)$:
            \[P_X(x) = \begin{cases} 
                \binom{32}{12} \left(\frac{1}{4}\right)^{12} \left(\frac{3}{4}\right)^{20} & \text{if } x = 12 \\
                0 & \text{otherwise}
            \end{cases}\]

            So $P(X = 12) = \binom{32}{12} \left(\frac{1}{4}\right)^{12} \left(\frac{3}{4}\right)^{20}$
        \item $P(7 < X < 12)$ (There is some ambiguity in whether 7 and 12 are included but unless indicated otherwise between \textbf{excludes} endpoints):
            \[P_X(x) = \begin{cases} 
                \binom{32}{x} \left(\frac{1}{4}\right)^{x} \left(\frac{3}{4}\right)^{32-x} & \text{if } x = 7, 8, 9, 10, 11, 12 \\
                0 & \text{otherwise}
            \end{cases}\]

            So $P(7 < X < 12) = \sum_{x=8}^{11} P_X(x) = \sum_{x=8}^{11} \binom{32}{x} \left(\frac{1}{4}\right)^{x} \left(\frac{3}{4}\right)^{32-x}$

        \item $P(Y = 20)$ (equivalent to 20 tails):
            \[P_Y(y) = \begin{cases} 
                \binom{32}{20} \left(\frac{3}{4}\right)^{20} \left(\frac{1}{4}\right)^{12} & \text{if } y = 20 \\
                0 & \text{otherwise}
            \end{cases}\]

            So $P(Y = 20) = \binom{32}{20} \left(\frac{3}{4}\right)^{20} \left(\frac{1}{4}\right)^{12}$

        \item $E(X) = np = 32 \cdot \frac{1}{4} = 8$

        \item $V(X) = npq = 32 \cdot \frac{1}{4} \cdot \frac{3}{4} = 6$
    \end{enumerate}

    \section*{Lecture 13: Tuesday 10/8/2024}

    (went over study guide for exam 1 $-$ I don't see a reason to put this here)


    \section*{Lecture 14: Thursday 10/10/2024}

    (Exam 1)

    \pagebreak

    \section*{Lecture 15: Tuesday 10/15/2024}

    \subsection*{Special Discrete Distributions}

    \begin{itemize}
        \item Bernoulli Distribution
        \item Geometric Distribution
        \item Binomial Distribution
        \item Hypergeometric Distribution
        \item Poisson Distribution
        \item Poisson Process
    \end{itemize}

    \subsubsection*{Hypergeometric Distribution}

    Suppose an experiment involves randomly selecting $n$ items from a population of size $N$ that contains $M$ successes.

    Let $X$ be a random variable that counts the number of successes in the sample.

    Then $X$ follows a hypergeometric distribution with parameters $N$, $M$, and $n$, denoted as:

    $X \sim \text{Hypergeometric}(N, M, n)$

    Where:
    \begin{itemize}
        \item $N$ is the total population size
        \item $M$ is the number of successes in the population
        \item $n$ is the number of items drawn from the population
    \end{itemize}

    The probability mass function is given by:

    \[P(X = x) = \frac{\binom{M}{x} \binom{N-M}{n-x}}{\binom{N}{n}}\]

    for $x = 0, 1, 2, ..., \min(n, M)$

    Note: The binomial distribution can approximate the hypergeometric distribution under suitable circumstances.

    \subsubsection*{Poisson Distribution}

    Let $\lambda > 0$ be fixed. A random variable $X$ has a Poisson distribution with parameter $\lambda$, written as $X \sim \text{Poisson}(\lambda)$, if:

    \[P_X(x) = P(X = x) = \frac{\lambda^x e^{-\lambda}}{x!} \quad \text{for } x = 0, 1, 2, ...\]

    Where $\lambda$ is the average number of successes per unit of time or space.

    Verify that $P_X(x)$ is a valid PMF:

    \textbf{Verification that $P_X(x)$ is a valid PMF:}

    \begin{enumerate}
        \item $P_X(x) \geq 0$ for all $x$:
            \begin{itemize}
                \item By convention, $P_X(x) = 0$ for $x \notin \{0, 1, 2, \ldots\}$
                \item For $x \in \mathbb{N} \cup \{0\}$, $P_X(x) > 0$ because:
                    \begin{itemize}
                        \item $e^{-\lambda} > 0$
                        \item $\lambda^x > 0$
                        \item $x! > 0$
                    \end{itemize}
            \end{itemize}
            Therefore, $P_X(x)$ is non-negative for all $x$.

        \item $\sum_{x=0}^{\infty} P_X(x) = 1$:
            \begin{align*}
                \sum_{x=0}^{\infty} P_X(x) &= \sum_{x=0}^{\infty} \frac{\lambda^x e^{-\lambda}}{x!} \\
                &= e^{-\lambda} \sum_{x=0}^{\infty} \frac{\lambda^x}{x!} \\
                &= e^{-\lambda} \cdot e^{\lambda} \\
                &= 1
            \end{align*}
    \end{enumerate}

    Therefore, $P_X(x)$ is a valid PMF.

    \textbf{Expected Value and Variance:}

    \begin{itemize}
        \item Expected Value:
            \begin{align*}
                E(X) &= \sum_{x=0}^{\infty} x \cdot P_X(x) \\
                &= \sum_{x=0}^{\infty} x \cdot \frac{\lambda^x e^{-\lambda}}{x!} \\
                &= \lambda e^{-\lambda} \sum_{x=1}^{\infty} \frac{\lambda^{x-1}}{(x-1)!} \\
                &= \lambda e^{-\lambda} \cdot e^{\lambda} \\
                &= \lambda
            \end{align*}

        \item Variance:
            \begin{align*}
                V(X) &= E(X^2) - (E(X))^2 \\
                &= \lambda + \lambda^2 - \lambda^2 \\
                &= \lambda
            \end{align*}
    \end{itemize}

    \textbf{Poisson Approximation to Binomial:}

    Let $X \sim \text{Bin}(n, p)$ and $Y \sim \text{Poisson}(np)$. Then for any subset $A \subseteq \{0, 1, 2, \ldots\}$:

    \[|P(X \in A) - P(Y \in A)| \leq np^2\]

    Note: $E(X) = E(Y) = np$

    Examples:
    \begin{itemize}
        \item For $n = 100$, $p = \frac{1}{2}$:
            \[|P(X \in A) - P(Y \in A)| \leq 100 \cdot \left(\frac{1}{2}\right)^2 = 25\]
        
        \item For $n = 100$, $p = \frac{1}{10^4}$:
            \[|P(X \in A) - P(Y \in A)| \leq 100 \cdot \left(\frac{1}{10^4}\right)^2 = \frac{1}{10^6}\]
    \end{itemize}

    The Poisson distribution can be used to approximate probabilities of rare events (when $np$ is small). This is known as the law of rare events.

    \textbf{Example:} Suppose a large factory with many workers experiences 3 accidents each month on average. Approximate the probability that a particular month has 2 accidents.

    Solution:
    \begin{itemize}
        \item Let $X$ be the number of accidents in a fixed month
        \item Assume $X \sim \text{Poisson}(3)$ since $E(X) = 3$
        \item $P(X = 2) = e^{-3} \frac{3^2}{2!} \approx 0.2240$
    \end{itemize}

    \textbf{Poisson Process:}

    A Poisson process models occurrences of events over time. A Poisson Process with intensity or rate $\lambda > 0$ is a collection of random points on $[0, \infty)$ with the following properties:

    \begin{enumerate}
        \item The points are distinct.
        \item The number of points in a bounded interval $I \subseteq [0, \infty)$, denoted by $N(I)$, follows a Poisson distribution with parameter $\lambda \cdot \text{length}(I)$.
        \item If $I_1, I_2, \ldots, I_n$ are non-overlapping intervals in $[0, \infty)$, then $N(I_1), N(I_2), \ldots, N(I_n)$ are independent random variables.
    \end{enumerate}

   \pagebreak

   \section*{Lecture 16: Thursday 10/17/2024}

   \subsection*{Poisson Process}

   \begin{tikzpicture}
   \draw[->] (0,0) -- (10,0) node[right] {$[0,\infty)$};
   \foreach \x in {1,3,4,6,8}
     \draw (\x,0.1) -- (\x,-0.1) node[below] {X};
   \end{tikzpicture}

   (X is a event that takes place)

   A Poisson process with intensity (rate) $\lambda > 0$ is a collection of random points on $[0, \infty)$ with the following properties:

   \begin{itemize}
     \item The points are distinct.
     \item The number of points in any interval $I \subseteq [0, \infty)$, denoted by $N(I)$, follows a Poisson distribution with parameter $\lambda \cdot \text{length}(I)$.
     \item If $I_1, I_2, \ldots, I_n$ are non-overlapping intervals in $[0, \infty)$, then $N(I_1), N(I_2), \ldots, N(I_n)$ are independent random variables.
   \end{itemize}

   \textbf{Example:} Suppose customers arrive at a store according to a Poisson process with intensity 5/hr. The store is open from 9am to 6pm.

   \begin{enumerate}
     \item[i)] Find the probability that no customer comes to the store within one hour of opening.
     
     $N([9, 10]) \sim \text{Poisson}(5)$
     
     $P(N([9, 10]) = 0) = e^{-5} \frac{5^0}{0!} = e^{-5}$

     \item[ii)] Find the probability that there are two customers between 9-10, three customers between 10-10:30, and five between 2-3:30.
     
     $P(N([9, 10]) = 2, N([10, 10:30]) = 3, N([14, 15:30]) = 5)$
     
     $= P(N([9, 10]) = 2) \cdot P(N([10, 10:30]) = 3) \cdot P(N([14, 15:30]) = 5)$
     
     Where:
     \begin{align*}
       N([9, 10]) &\sim \text{Poisson}(5) \\
       N([10, 10:30]) &\sim \text{Poisson}(2.5) \\
       N([14, 15:30]) &\sim \text{Poisson}(7.5)
     \end{align*}
     
     Required probability:
     \begin{align*}
       &= \frac{5^2}{2!} e^{-5} \cdot \frac{2.5^3}{3!} e^{-2.5} \cdot \frac{7.5^5}{5!} e^{-7.5} \\
       &= e^{-15} \cdot \frac{5^2}{2!} \cdot \frac{2.5^3}{3!} \cdot \frac{7.5^5}{5!}
     \end{align*}

     \item[iii)] Find the probability that three customers arrive between 10-10:30 given 12 customers showed up between 10-12.
     
     \begin{align*}
         P(N([10, 10.5]) = 3 \mid N([10, 12]) = 12) &= \frac{P(N([10, 10.5]) = 3, N([10.5, 12]) = 9)}{P(N([10, 12]) = 12)} \\[1ex]
         &= \frac{P(N([10, 10.5]) = 3) \cdot P(N([10.5, 12]) = 9)}{P(N([10, 12]) = 12)} \\[1ex]
         &= \frac{e^{-2.5} \frac{2.5^3}{3!} \cdot e^{-7.5} \frac{7.5^9}{9!}}{e^{-10} \frac{10^{12}}{12!}} \\[1ex]
         &= \frac{2.5^3 \cdot 7.5^9 \cdot 12!}{3! \cdot 9! \cdot 10^{12}}
     \end{align*}
    \end{enumerate}

    \subsection*{Special Distributions}

    \subsubsection*{Continuous Distributions}

    \begin{itemize}
        \item Uniform Distribution
        \item Exponential Distribution
        \item Normal Distribution
    \end{itemize}

    \subsubsection*{Uniform Distribution}

    In the discrete case, uniform meant that each individual outcome was equally likely.

    For any continuous random variable $X$, $P(X = a) = \int_{a}^{a} f(x) dx = 0$ for any specific value $a$.

    So directly extending this idea doesn't work. For a continuous random variable, a reasonable way to extend this is to say that no one region should have a higher probability of producing an outcome as any other as long as both regions have the same length.

    If $X \sim U([a, b])$, then:

    \[
    f_X(x) = \begin{cases} 
        \frac{1}{b-a} & \text{if } a \leq x \leq b \\
        0 & \text{otherwise}
    \end{cases}
    \]

    \[
    F_X(x) = \begin{cases} 
        0 & \text{if } x < a \\
        \frac{x-a}{b-a} & \text{if } a \leq x \leq b \\
        1 & \text{if } x > b
    \end{cases}
    \]

    % PDF of Uniform Distribution
    \begin{figure}[h]
        \centering
        \begin{tikzpicture}
            \begin{axis}[
                width=0.45\textwidth,
                height=0.3\textwidth,
                xlabel=$x$,
                ylabel=$f_X(x)$,
                xmin=0, xmax=4,
                ymin=0, ymax=0.6,
                xtick={1,3},
                xticklabels={$a$,$b$},
                ytick={0,0.5},
                yticklabels={0,$\frac{1}{b-a}$},
                title={PDF of $U(a,b)$},
                axis lines=left,
                clip=false
            ]
                \addplot[
                    domain=1:3,
                    fill=blue!20,
                    draw=blue,
                    thick
                ] {0.5} \closedcycle;
                \draw[dashed] (axis cs:1,0) -- (axis cs:1,0.5);
                \draw[dashed] (axis cs:3,0) -- (axis cs:3,0.5);
                \addplot[domain=0:1, draw=black, thick] {0};
                \addplot[domain=3:4, draw=black, thick] {0};
            \end{axis}
        \end{tikzpicture}
        \hfill
        \begin{tikzpicture}
            \begin{axis}[
                width=0.45\textwidth,
                height=0.3\textwidth,
                xlabel=$x$,
                ylabel=$F_X(x)$,
                xmin=0, xmax=4,
                ymin=0, ymax=1.1,
                xtick={1,3},
                xticklabels={$a$,$b$},
                ytick={0,1},
                title={CDF of $U(a,b)$},
                axis lines=left,
                clip=false
            ]
                \addplot[domain=0:1, draw=blue, thick] {0};
                \addplot[
                    domain=1:3,
                    draw=blue,
                    thick
                ] {(x-1)/2};
                \addplot[domain=3:4, draw=blue, thick] {1};
            \end{axis}
        \end{tikzpicture}
        \caption{PDF and CDF of Uniform Distribution $U(a,b)$}
    \end{figure}

    \[
    E(X) = \int_{-\infty}^{\infty} x f_X(x) dx = \int_{a}^{b} x \frac{1}{b-a} dx = \frac{a+b}{2}
    \]
    
    \[
    V(X) = E(X^2) - (E(X))^2 = \int_{-\infty}^{\infty} x^2 f_X(x) dx - (\frac{a+b}{2})^2 = \frac{(b-a)^2}{12}
    \]

    \subsubsection*{Exponential Distribution}

    The exponential distribution is related to the Poisson distribution.

    We say that $X \sim \text{Exp}(\lambda)$ if:

    \[
    f_X(x) = \begin{cases} 
        \lambda e^{-\lambda x} & \text{if } x \geq 0 \\
        0 & \text{otherwise}
    \end{cases}
    \]

    \begin{figure}[h]
        \centering
        \begin{tikzpicture}
            \begin{axis}[
                width=0.8\textwidth,
                height=0.5\textwidth,
                xlabel=$x$,
                ylabel=$f_X(x)$,
                xmin=0, xmax=5,
                ymin=0, ymax=1.2,
                samples=200,
                domain=0:5,
                legend pos=north east,
                title={PDF of Exponential Distribution},
                grid=major,
                axis lines=left,
                ytick={0,0.2,0.4,0.6,0.8,1,1.2},
                xtick={0,1,2,3,4,5}
            ]
                \addplot[red, thick, smooth] {0.5*exp(-0.5*x)};
                \addlegendentry{$\lambda = 0.5$}
                
                \addplot[blue, thick, smooth] {exp(-x)};
                \addlegendentry{$\lambda = 1$}
                
                \addplot[green!60!black, thick, smooth] {2*exp(-2*x)};
                \addlegendentry{$\lambda = 2$}
            \end{axis}
        \end{tikzpicture}
        \caption{Probability Density Function (PDF) of Exponential Distribution for different $\lambda$ values}
    \end{figure}

    The exponential distribution is often used to model wait times, with $\lambda = \frac{1}{\text{average wait}}$.

    \[
    E(X) = \frac{1}{\lambda}
    \]

    \[
    V(X) = \frac{1}{\lambda^2}
    \]

    \[
    F_X(x) = \begin{cases} 
        0 & \text{if } x < 0 \\
        1 - e^{-\lambda x} & \text{if } x \geq 0
    \end{cases}
    \]

    \begin{figure}[h]
        \centering
        \begin{tikzpicture}
            \begin{axis}[
                width=0.8\textwidth,
                height=0.4\textwidth,
                xlabel=$x$,
                ylabel=$F_X(x)$,
                xmin=0, xmax=5,
                ymin=0, ymax=1,
                samples=100,
                domain=0:5,
                legend pos=south east,
                title={CDF of Exponential Distribution}
            ]
                \addplot[red, thick] {1 - exp(-0.5*x)};
                \addlegendentry{$\lambda = 0.5$}
                
                \addplot[blue, thick] {1 - exp(-x)};
                \addlegendentry{$\lambda = 1$}
                
                \addplot[green, thick] {1 - exp(-2*x)};
                \addlegendentry{$\lambda = 2$}
            \end{axis}
        \end{tikzpicture}
        \caption{Cumulative Distribution Function (CDF) of Exponential Distribution for different $\lambda$ values}
    \end{figure}

    \[
    F_X(x) = \int_{-\infty}^{x} f_X(t) dt = 1 - e^{-\lambda x}
    \]

    \[
    F_X(x) = \int_{0}^{x} \lambda e^{-\lambda t} dt = 1 - e^{-\lambda x}
    \]

    \subsubsection*{Example: Restaurant Wait Times}

    The average wait time at a restaurant to be seated is 2 minutes. Two customers walk into the restaurant at different times of the day. What is the probability they both were seated within 4 minutes of their arrival? (Assume that the wait times are exponentially distributed)

    Let $X_1 \sim \text{Exp}(0.5)$ be the wait time for the 1st customer and $X_2 \sim \text{Exp}(0.5)$ be the wait time for the 2nd customer.

    \begin{align*}
    P(X_1 \leq 4, X_2 \leq 4) &= P(X_1 \leq 4) \cdot P(X_2 \leq 4) \quad \text{(Assuming independence)} \\
    &= (1 - e^{-0.5 \cdot 4}) \cdot (1 - e^{-0.5 \cdot 4}) \\
    &= (1 - e^{-2})^2
    \end{align*}

    Note: It's often faster to use the CDF instead of computing integrals in this case.

    \pagebreak

    \section*{Lecture 17: Tuesday 10/22/2024}

    \subsection*{Normal Distribution}

    The random variable $X$ has a normal distribution with mean $\mu$ and variance $\sigma^2$ (denoted as $X \sim N(\mu, \sigma^2)$) if:
    
    X has a pdf given by:

    \[
    f_X(x) = \frac{1}{\sigma \sqrt{2\pi}} e^{-\frac{(x-\mu)^2}{2\sigma^2}} \text{ where } x \in \mathbb{R}
    \]
    

    We begin by examining the standard normal distribution, where $\mu = 0$ and $\sigma^2 = 1$.

    For $X \sim N(0, 1)$, the probability density function (pdf) is given by:

    \[
    f_X(x) = \frac{1}{\sqrt{2\pi}} e^{-\frac{x^2}{2}}, \quad x \in \mathbb{R}
    \]

    Since there is no straightforward antiderivative for this function, evaluating the integral directly poses challenges.

    To overcome this issue, we utilize pre-calculated values (typically provided in tables) for $P(Z \leq z)$, where $Z \sim N(0, 1)$.

    It is conventional to denote $P(Z \leq z)$ as $\Phi(z)$. In other words:

    \[
    \Phi(z) = P(Z \leq z) = F_Z(z) \quad \text{for } Z \sim N(0, 1)
    \]

    $\Phi(z)$ is referred to as the cumulative distribution function (cdf) of the standard normal distribution.

    \textbf{Examples:}
    \begin{itemize}
        \item $P(Z \leq 1.19) = \Phi(1.19) = 0.8830$
        
        \item $P(-1.23 \leq Z \leq 1.43)$ 
              \begin{align*}
              &= P(Z \leq 1.43) - P(Z \leq -1.23) \\
              &= \Phi(1.43) - \Phi(-1.23) \\
              &= 0.9236 - 0.1093 \\
              &= 0.8143
              \end{align*}
    \end{itemize}

    \textbf{Important property:} The standard normal distribution is symmetric about 0, i.e., $f_X(x) = f_X(-x)$ for all $x$ so $f_X(x)$ is even.

    \textbf{Handling Non-Standard Normal Distributions:}

    For non-standard normal distributions, we use integration by substitution.

    Let $Z = \frac{X - \mu}{\sigma}$, where $X \sim N(\mu, \sigma^2)$.

    \textbf{Exercise:} Show that:

    \[
    \int_{a}^{b} \frac{1}{\sigma \sqrt{2\pi}} e^{-\frac{1}{2} (\frac{x-\mu}{\sigma})^2} dx = \int_{\frac{a-\mu}{\sigma}}^{\frac{b-\mu}{\sigma}} \frac{1}{\sqrt{2\pi}} e^{-\frac{1}{2} z^2} dz
    \]
    We compute probabilities for $X \sim N(\mu, \sigma^2)$ in terms of $Z \sim N(0, 1)$ using the integration substitution above.

    If $X \sim N(\mu, \sigma^2)$, then $Z = \frac{X - \mu}{\sigma} \sim N(0, 1)$, and:

    \[
    P(a < X < b) = P\left(\frac{a - \mu}{\sigma} < Z < \frac{b - \mu}{\sigma}\right) = \Phi\left(\frac{b - \mu}{\sigma}\right) - \Phi\left(\frac{a - \mu}{\sigma}\right)
    \]

    \textbf{Example:} Suppose that the heights of females on a particular island can be modeled using a normal distribution with mean 150 cm and variance 25 cm$^2$.

    What is the probability that a randomly selected female has a height that falls between 145 cm and 160 cm?

    Given: $X \sim N(150, 25)$

    We want to find: $P(145 < X < 160)$

    Solution:
    Let $Z = \frac{X - 150}{5}$, then:

    \begin{align*}
    P(145 < X < 160) &= P\left(\frac{145 - 150}{5} < Z < \frac{160 - 150}{5}\right) \\
    &= P(-1 < Z < 2) \\
    &= \Phi(2) - \Phi(-1)
    \end{align*}

    = plug in values from the table.
    
    \textbf{Example:} Suppose $X \sim N(\mu, \sigma^2)$. What is the probability that observation falls within a standard deviation of the mean?

    $X \sim N(\mu, \sigma^2)$

    \begin{align*}
    P(|X - \mu| < \sigma) &= P(-\sigma < X - \mu < \sigma) \\
    &= P(\mu - \sigma < X < \mu + \sigma)
    \end{align*}

    Let $Z = \frac{X - \mu}{\sigma}$, then $Z \sim N(0, 1)$

    \begin{align*}
    P(|X - \mu| < \sigma) &= P\left(\frac{\mu - \sigma - \mu}{\sigma} < Z < \frac{\mu + \sigma - \mu}{\sigma}\right) \\
    &= P(-1 < Z < 1) \\
    &= \Phi(1) - \Phi(-1) \\
    &= 0.8413 - 0.1587 \\
    &= 0.6826
    \end{align*}

    \subsection*{Random Vectors / Joint Distributions}

    A random vector $\underline{X} : \Omega \rightarrow \mathbb{R}^n$ is given by:

    \[\underline{X} = \begin{pmatrix} X_1 \\ \vdots \\ X_n \end{pmatrix}\]

    where $X_1, \ldots, X_n : \Omega \rightarrow \mathbb{R}$.

    \textbf{Example:} Let $\Omega = \{\text{people in a particular hospital at a given fixed point in time}\}$.

    \begin{itemize}
        \item $X_1(\omega) = \text{blood pressure (systolic) of }\omega$
        \item $X_2(\omega) = \text{weight of }\omega$
        \item $X_3(\omega) = \text{height of }\omega$
    \end{itemize}

    Then, $\underline{X} = \begin{pmatrix} X_1 \\ X_2 \\ X_3 \end{pmatrix}$

    \textbf{Example:} Cat pictures in machine learning algorithms

    Let $\Omega = \{\text{set of cat pictures of a fixed type}\}$

    For a black and white image with 32x32 pixels:
    \begin{itemize}
        \item Each pixel is represented by a random variable
        \item Total number of random variables = $32 \times 32 = 1024$
    \end{itemize}

    Thus, we have a random vector $\underline{X} : \Omega \rightarrow \mathbb{R}^{1024}$

    \begin{figure}[h]
        \centering
        \begin{tikzpicture}
            \draw (0,0) grid[step=0.1875] (3,3);
            \draw[ultra thick] (0,0) rectangle (3,3);
            \fill[red] (1.125,1.875) rectangle (1.3125,2.0625);
            \node at (1.21875,2.15) {$X_i$};
            \node at (1.5,-0.5) {32x32 pixels};
        \end{tikzpicture}
        \caption{Representation of a 32x32 pixel image with highlighted pixel $X_i$}
    \end{figure}

    Let $\underline{X} = (X_1, X_2, \ldots, X_{1024})$ be a random vector where:

    \begin{itemize}
        \item $X_i(\omega)$ represents the brightness/darkness of the $i$-th pixel for picture $\omega$
        \item $\omega$ denotes a specific picture in the sample space
    \end{itemize}

    In image classification algorithms, the goal is to compute $P(\text{label} \mid \text{picture})$. For example:

    \begin{itemize}
        \item label $\in \{\text{cat}, \text{not cat}\}$
        \item picture is represented by the random vector $\underline{X}$
    \end{itemize}

    Thus, we can express this probability as:

    \[P(\text{label} = \text{cat} \mid \text{picture}) = P(\text{label} = \text{cat} \mid \underline{X} = \underline{x})\]

    \textbf{Key Ideas:}
    \begin{itemize}
        \item A single random variable is often insufficient to describe complex problems.
        \item Many real-world applications require analyzing how multiple random variables interact when considered together.
    \end{itemize}

    \section*{Lecture 18: Thursday 10/24/2024}
 
    \subsection*{Random Vectors}

    In many situations, it is not sufficient to keep track of just one random quantity - we need to track several random quantities simultaneously. This leads us to the concept of random vectors.

    \textbf{Definition:} A random vector is an ordered collection of random variables that maps from a sample space $\Omega$ to a multi-dimensional real space:

    \begin{align*}
        \text{Individual components:} \quad & X_1, \ldots, X_n : \Omega \rightarrow \mathbb{R} \\
        \text{Vector notation:} \quad & \underline{X} = (X_1, \ldots, X_n)^T \\
        \text{Overall mapping:} \quad & \underline{X} : \Omega \rightarrow \mathbb{R}^n
    \end{align*}

    \textbf{Computing Probabilities for Random Vectors}

    To understand how to compute probabilities for random vectors, let's first review the simpler case of a single random variable:

    For a single random variable $X$:
    \begin{itemize}
        \item $X$ maps from $\Omega$ to $\mathbb{R}$
        \item For any subset $A \subseteq \mathbb{R}$
        \item The probability is: $P(X \in A) = P(\{\omega \in \Omega : X(\omega) \in A\})$
    \end{itemize}

    This concept extends naturally to random vectors. For a two-dimensional random vector $\underline{X} = \begin{pmatrix} X \\ Y \end{pmatrix}$:
    
    \[ P(\underline{X} \in A) = P(\{\omega \in \Omega : \underline{X}(\omega) \in A\}) = P\left(\left\{\omega : \begin{pmatrix} X(\omega) \\ Y(\omega) \end{pmatrix} \in A\right\}\right) \]

    where $A$ is now a subset of $\mathbb{R}^2$. For example, $A$ could be a circle, rectangle, or any other two-dimensional region:

    \begin{center}
    \begin{tikzpicture}
        % Draw axes from origin
        \draw[->] (-1,0) -- (4,0) node[right] {$x$};
        \draw[->] (0,-1) -- (0,4) node[above] {$y$};
        
        % Draw circle centered at (2,2) with radius 1
        \draw[fill=gray!20] (2,2) circle (1);
        
        % Label the region A
        \node at (3.5,2.7) {$A \subseteq \mathbb{R}^2$};
        
        % Draw and label point (X(ω), Y(ω))
        \draw[fill=red] (1.5,2) circle (0.05);
        \node[right] at (1.6,2.1) {$(X(\omega), Y(\omega))$};
        
        % Add caption below
        \node[below] at (3,-0.5) {Example: $A$ is a circle in $\mathbb{R}^2$ containing point $(X(\omega), Y(\omega))$};
    \end{tikzpicture}
    \end{center}

    We would like to do the same thing with a random vector $\underline{X} = \begin{pmatrix} X \\ Y \end{pmatrix}$.

    We introduce the notions of joint probability mass functions and joint probability density functions for this purpose.

    \subsection*{Joint Probability Mass Function (PMF)}

    The joint PMF for a random vector $\begin{pmatrix} X \\ Y \end{pmatrix}$ is the function $P_{X,Y}(x,y)$ such that:

    \[
        P_{X,Y}(x,y) = P(X = x, Y = y)
    \]

    Note: A discrete random vector is one that takes countably many values.

    \textbf{Example:} Consider an experiment consisting of rolling two fair dice.
    \begin{itemize}
        \item Let $X_1$ be a random variable tracking the first die's outcome
        \item Let $X_2$ be a random variable tracking the second die's outcome
    \end{itemize}

    The sample space is:
    \[ \Omega = \{(i,j) : i,j \in \{1,2,3,4,5,6\}\} \]

    And the random variables are defined as:
    \begin{align*}
        X_1(i,j) &= i \quad \text{(first die outcome)} \\
        X_2(i,j) &= j \quad \text{(second die outcome)}
    \end{align*}

    The joint PMF of $X_1$ and $X_2$ is:
    \[
    P_{X_1,X_2}(x_1,x_2) = 
    \begin{cases}
        \frac{1}{36} & \text{if } x_1,x_2 \in \{1,2,3,4,5,6\} \\
        0 & \text{otherwise}
    \end{cases}
    \]

    This reflects that each possible outcome $(x_1,x_2)$ has equal probability $\frac{1}{36}$ since the dice are fair.

    Let $\underline{X} = \begin{pmatrix} X_1 \\ X_2 \end{pmatrix}$ be our random vector.

    We want to compute $P(\underline{X} \in [4,\infty) \times [5,\infty))$, which represents the probability that $X_1 \geq 4$ and $X_2 \geq 5$ simultaneously.

    \begin{center}
    \begin{tikzpicture}[scale=0.8]
        % Axes
        \draw[->] (0,0) -- (7,0) node[right] {$x_1$};
        \draw[->] (0,0) -- (0,7) node[above] {$x_2$};
        
        % Grid
        \foreach \x in {1,...,6} {
            \draw[gray!30] (\x,0) -- (\x,6);
            \draw[gray!30] (0,\x) -- (6,\x);
        }
        
        % Region shading with gradient
        \fill[left color=blue!20, right color=blue!5] (4,5) rectangle (6.8,6.8);
        \fill[bottom color=blue!20, top color=blue!5] (4,5) rectangle (6.8,6.8);
        
        % Arrows indicating infinity
        \draw[->, thick] (6.5,5.5) -- (7.2,5.5);
        \draw[->, thick] (4.5,6.5) -- (4.5,7.2);
        
        % Labels
        \node[below] at (4,0) {4};
        \node[left] at (0,5) {5};
        
        % Region label
        \node at (5,5.5) {$[4,\infty) \times [5,\infty)$};
        
        % Infinity symbols
        \node at (7.5,5.5) {$\infty$};
        \node at (4.5,7.5) {$\infty$};
    \end{tikzpicture}
    \end{center}


    Key equation: 
    \[
    P(\underline{X} \in A) = \sum_{(\underline{x} \in A)} P_{\underline{X}}(\underline{x}) where P_{\underline{X}} > 0
    \]


    \begin{center}
    \begin{tikzpicture}[scale=0.8]
        % Axes
        \draw[->] (0,0) -- (7,0) node[right] {$x_1$};
        \draw[->] (0,0) -- (0,7) node[above] {$x_2$};
        
        % Grid
        \foreach \x in {1,...,6} {
            \draw[gray!30] (\x,0) -- (\x,6);
            \draw[gray!30] (0,\x) -- (6,\x);
        }
        
        % Region shading with gradient
        \fill[left color=blue!20, right color=blue!5] (4,5) rectangle (6.8,6.8);
        \fill[bottom color=blue!20, top color=blue!5] (4,5) rectangle (6.8,6.8);
        
        % Points in the region
        \foreach \x in {4,5,6} {
            \foreach \y in {5,6} {
                \fill[red] (\x,\y) circle (2pt);
            }
        }
        
        % Highlight (6,6) point
        \fill[red!80] (6,6) circle (3pt);
        \node[above right] at (6,6) {$(6,6)$};
        
        % Arrows indicating infinity
        \draw[->, thick] (6.5,5.5) -- (7.2,5.5);
        \draw[->, thick] (4.5,6.5) -- (4.5,7.2);
        
        % Labels
        \node[below] at (4,0) {4};
        \node[left] at (0,5) {5};
        
        % Region label
        \node at (5,5.5) {$[4,\infty) \times [5,\infty)$};
        
        % Infinity symbols
        \node at (7.5,5.5) {$\infty$};
        \node at (4.5,7.5) {$\infty$};
    \end{tikzpicture}
    \end{center}

    \noindent
    For region $A = [4,\infty) \times [5,\infty)$, we need to find the probability that our random variable falls in this region.
    \[P(\underline{X} \in A) = \sum_{(\underline{x} \in A)} P_{\underline{X}}(\underline{x})\]

    \noindent
    Looking at the graph above, we can see that region $A$ contains these specific points:
    \[\underline{X} \in \{(4,5), (4,6), (5,5), (5,6), (6,5), (6,6)\}\]

    \noindent
    Since we're rolling two fair dice, each possible outcome has an equal probability of $\frac{1}{36}$. Let's add up the probabilities:
    \begin{align*}
        P(\underline{X} \in A) &= \sum_{(x_1,x_2) \in A} P_{X_1,X_2}(x_1,x_2) \\[0.5em]
        &= P_{X_1,X_2}(4,5) + P_{X_1,X_2}(4,6) + P_{X_1,X_2}(5,5) \\
        &\quad + P_{X_1,X_2}(5,6) + P_{X_1,X_2}(6,5) + P_{X_1,X_2}(6,6) \\[0.5em]
        &= \underbrace{\frac{1}{36} + \frac{1}{36} + \frac{1}{36} + \frac{1}{36} + \frac{1}{36} + \frac{1}{36}}_{\text{We have 6 points in region A, each with probability }\frac{1}{36}} \\[0.5em]
        &= \frac{6}{36} = \frac{1}{6}
    \end{align*}

    \textbf{Important Notes:} 
    \begin{itemize}
        \item Just like with a regular probability mass function (PMF), we can find probabilities by adding up values from a joint PMF
        \item For any joint PMF, all probabilities must be non-negative ($P_{X,Y}(x,y) \geq 0$) and sum to 1: $\sum_{(x, y) \in \mathbb{R}^2} P_{X,Y}(x,y) = 1$
    \end{itemize}

    \subsection*{Example: Coin Toss and Die Roll}
    Let's work through a clear example. Consider this two-step experiment:
    \begin{enumerate}
        \item First, we toss a fair coin
        \item Then, based on the coin result:
            \begin{itemize}
                \item If we get heads (H): We roll a regular fair 6-sided die
                \item If we get tails (T): We roll a fair 4-sided die
            \end{itemize}
    \end{enumerate}

    Let's define our variables:
    \begin{itemize}
        \item Let $X$ be the coin toss result (H or T)
        \item Let $Y$ be the number we get from the die roll
    \end{itemize}

    All possible outcomes are:
    \[ \Omega = \{(H,1), (H,2), (H,3), (H,4), (H,5), (H,6), (T,1), (T,2), (T,3), (T,4)\} \]

    \textbf{Let's find the joint PMF $P_{X,Y}(x,y)$ step by step:}

    To find this, we need two pieces:
    \begin{itemize}
        \item The probability of getting each coin result ($P_X(x)$)
        \item The probability of getting each die roll given the coin result ($P_{Y|X}(y|x)$)
    \end{itemize}

    \textbf{Step 1: Probability of coin results ($P_X(x)$)}
    Since we're using a fair coin:
    \[ P_X(x) = \begin{cases}
        \frac{1}{2} & \text{if } x \text{ is H or T} \\
        0 & \text{for any other value}
    \end{cases} \]

    \textbf{Step 2: Probability of die rolls given coin result ($P_{Y|X}(y|x)$)}
    \[ P_{Y|X}(y|x) = \begin{cases}
        \frac{1}{6} & \text{if we got heads (H) and } y \text{ is 1,2,3,4,5, or 6} \\
        \frac{1}{4} & \text{if we got tails (T) and } y \text{ is 1,2,3, or 4} \\
        0 & \text{for any other combination}
    \end{cases} \]

    \textbf{Note:} This only becomes a proper PMF after you specify whether you got heads or tails.

    \textbf{Step 3: Putting it together - The Joint PMF}
    We multiply the probabilities from steps 1 and 2:
    $P_{X,Y}(x,y) = P_X(x) \cdot P_{Y|X}(y|x)$
    \[ P_{X,Y}(x,y) = \begin{cases}
        \frac{1}{12} & \text{if we got heads (H) and } y \text{ is 1,2,3,4,5, or 6} \\
        \frac{1}{8} & \text{if we got tails (T) and } y \text{ is 1,2,3, or 4} \\
        0 & \text{for any other combination}
    \end{cases} \]

    \textbf{Let's verify this is correct:} 
    All probabilities should sum to 1:
    \[ \underbrace{6 \cdot \frac{1}{12}}_{\text{6 possible outcomes with H}} + \underbrace{4 \cdot \frac{1}{8}}_{\text{4 possible outcomes with T}} = \frac{1}{2} + \frac{1}{2} = 1 \]

    \noindent
    \textbf{Understanding Conditional Probabilities with Multiple Variables:}
    
    When we have more than two variables, we can condition on multiple events:
    \begin{itemize}
        \item $P_{X_1|X_2,X_3}(x_1|x_2,x_3)$ means ``probability of $X_1$ given we know both $X_2$ and $X_3$"
        \item $P_{X_1,X_3|X_2}(x_1,x_3|x_2)$ means ``joint probability of $X_1$ and $X_3$ given we know $X_2$"
    \end{itemize}

    \vspace{0.3cm}
    \noindent
    \textbf{Example: Finding the Probability of Rolling a 1}
    Let's find $P_Y(1)$ (the probability of rolling a 1 regardless of the coin flip):
    \begin{align*}
        P_Y(y_0) &= \sum_{x} P_{X,Y}(x,y_0) \quad \text{(Add up probabilities for all possible coin results)} \\[0.2cm]
        P_Y(1) &= \sum_{x} P_{X,Y}(x,1) \\[0.2cm]
        &= P_{X,Y}(H,1) + P_{X,Y}(T,1) \quad \text{(Probability with heads + Probability with tails)} \\[0.2cm]
        &= \frac{1}{12} + \frac{1}{8} = \frac{5}{24}
    \end{align*}

    \vspace{0.3cm}
    \noindent
    \pagebreak
    \textbf{Understanding Independent Random Variables:}
    
    Two random variables $X$ and $Y$ are independent if knowing one tells us nothing about the other.
    Mathematically, this means their joint PMF equals the product of their individual PMFs:
    \[
        P_{X,Y}(x,y) = P_X(x)P_Y(y)
    \]

    In our coin and die example, $X$ and $Y$ are NOT independent because:
    \begin{itemize}
        \item Knowing we got tails (X = T) tells us Y can't be 5 or 6
        \item Knowing we got Y = 6 tells us we must have gotten heads
    \end{itemize}

    \section*{Lecture 19: Tuesday 10/29/2024}






























\end{document}
